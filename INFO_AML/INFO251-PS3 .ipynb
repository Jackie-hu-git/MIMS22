{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 3\n",
    "\n",
    "### Before You Start\n",
    "\n",
    "Make sure the following libraries load correctly (hit Ctrl-Enter). Note that while you are loading several powerful libraries, including machine learning libraries, the goal of this problem set is to implement several algorithms from scratch. In particular, you should *not* be using any built-in libraries for nearest neighbors, distance metrics, or cross-validation -- your mission is to write those algorithms in Python! Part 1 will be relatively easy; Part 2 will take more time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Introduction to the assignment\n",
    "\n",
    "For this assignment, you will be using the [Boston Housing Prices Data Set](http://www.kellogg.northwestern.edu/faculty/weber/emp/_session_3/boston.htm).  Please read about the dataset carefully before continuing.  Use the following commands to load the dataset:\n",
    "\n",
    "*NOTE - This dataset is similar to the one you used in PS1; we are just using a different method to load it this time. The column names and their order will remain the same for this dataset as was in PS1.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Boston housing data set\n",
    "data = np.loadtxt('data.txt')\n",
    "target = np.loadtxt('target.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Experimental Setup\n",
    "\n",
    "The goal of the next few sections is to design an experiment to predict the median home value for an instance in the data.\n",
    "Before beginning the \"real\" work, refamiliarize yourself with the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Begin by writing a function to compute the Root Mean Squared Error for a list of numbers\n",
    "\n",
    "You can find the sqrt function in the Numpy package. Furthermore the details of RMSE can be found on [Wikipedia](http://en.wikipedia.org/wiki/Root-mean-square_deviation). Do not use a built-in function  to compute RMSE, other than numpy functions like `sqrt` and if needed, `sum` or other relevant ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "compute_rmse\n",
    "\n",
    "Given two arrays, one of actual values and one of predicted values,\n",
    "compute the Roote Mean Squared Error\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "predictions : array\n",
    "    Array of numerical values corresponding to predictions for each of the N observations\n",
    "\n",
    "yvalues : array\n",
    "    Array of numerical values corresponding to the actual values for each of the N observations\n",
    "\n",
    "Returns\n",
    "-------\n",
    "rmse : int\n",
    "    Root Mean Squared Error of the prediction\n",
    "\n",
    "Example\n",
    "-------\n",
    ">>> print(compute_rmse((2,2,3),(0,2,6)))\n",
    "2.08\n",
    "\"\"\"\n",
    "def compute_rmse(predictions, yvalues):\n",
    "    # your code here\n",
    "    n = len(yvalues)\n",
    "    np_p = np.array(predictions)\n",
    "    np_y = np.array(yvalues)\n",
    "    mse = (np.sum((np_y - np_p)**2))/n\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0816659994661326"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_rmse((2,2,3),(0,2,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0816659994661326\n"
     ]
    }
   ],
   "source": [
    "#sanity check\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(np.sqrt(mean_squared_error((0,2,6),(2,2,3))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Divide your data into training and testing datasets\n",
    "\n",
    "Randomly select 75% of the data and put this in a training dataset (call this \"bdata_train\"), and place the remaining 25% in a testing dataset (call this \"bdata_test\"). Do not use built-in functions.\n",
    "\n",
    "To perform any randomized operation, only use functions in the *numpy library (np.random)*. Do not use other packages for random functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.218960</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.629288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.869420</td>\n",
       "      <td>6.875396</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.347275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>15.534711</td>\n",
       "      <td>397.462329</td>\n",
       "      <td>5.715647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.141576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.315612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.549711</td>\n",
       "      <td>6.499894</td>\n",
       "      <td>78.9</td>\n",
       "      <td>5.315684</td>\n",
       "      <td>2.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>17.914131</td>\n",
       "      <td>397.012611</td>\n",
       "      <td>9.338417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.380457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.340354</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.697928</td>\n",
       "      <td>7.263489</td>\n",
       "      <td>61.1</td>\n",
       "      <td>5.356935</td>\n",
       "      <td>2.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>17.919989</td>\n",
       "      <td>396.628236</td>\n",
       "      <td>4.142473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.313563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.562407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.599629</td>\n",
       "      <td>7.209732</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.103983</td>\n",
       "      <td>3.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>18.979527</td>\n",
       "      <td>398.564784</td>\n",
       "      <td>3.239272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.497337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.476077</td>\n",
       "      <td>7.184111</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.264372</td>\n",
       "      <td>3.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>18.708888</td>\n",
       "      <td>399.487766</td>\n",
       "      <td>6.115159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.205345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.992590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.686750</td>\n",
       "      <td>6.895386</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.805111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>21.325449</td>\n",
       "      <td>395.822256</td>\n",
       "      <td>9.795056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.120722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.994115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583991</td>\n",
       "      <td>6.313574</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.652694</td>\n",
       "      <td>1.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>21.032632</td>\n",
       "      <td>398.559567</td>\n",
       "      <td>9.785685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.226099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.254201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.689092</td>\n",
       "      <td>7.199346</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.348891</td>\n",
       "      <td>1.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>21.042043</td>\n",
       "      <td>398.026747</td>\n",
       "      <td>5.831161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.139833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.054379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.650875</td>\n",
       "      <td>7.065029</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.783274</td>\n",
       "      <td>1.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>21.105130</td>\n",
       "      <td>395.290366</td>\n",
       "      <td>6.890841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.183073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.282788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.783073</td>\n",
       "      <td>6.353149</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.847304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>21.326959</td>\n",
       "      <td>400.822740</td>\n",
       "      <td>8.106447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM    ZN      INDUS  CHAS       NOX        RM   AGE       DIS  RAD  \\\n",
       "0    0.218960  18.0   2.629288   0.0  0.869420  6.875396  65.2  4.347275  1.0   \n",
       "1    0.141576   0.0   7.315612   0.0  0.549711  6.499894  78.9  5.315684  2.0   \n",
       "2    0.380457   0.0   7.340354   0.0  0.697928  7.263489  61.1  5.356935  2.0   \n",
       "3    0.313563   0.0   2.562407   0.0  0.599629  7.209732  45.8  6.103983  3.0   \n",
       "4    0.330105   0.0   2.497337   0.0  0.476077  7.184111  54.2  6.264372  3.0   \n",
       "..        ...   ...        ...   ...       ...       ...   ...       ...  ...   \n",
       "501  0.205345   0.0  11.992590   0.0  0.686750  6.895386  69.1  2.805111  1.0   \n",
       "502  0.120722   0.0  11.994115   0.0  0.583991  6.313574  76.7  2.652694  1.0   \n",
       "503  0.226099   0.0  12.254201   0.0  0.689092  7.199346  91.0  2.348891  1.0   \n",
       "504  0.139833   0.0  12.054379   0.0  0.650875  7.065029  89.3  2.783274  1.0   \n",
       "505  0.183073   0.0  12.282788   0.0  0.783073  6.353149  80.8  2.847304  1.0   \n",
       "\n",
       "       TAX    PTRATIO           B     LSTAT  \n",
       "0    307.0  15.534711  397.462329  5.715647  \n",
       "1    255.0  17.914131  397.012611  9.338417  \n",
       "2    243.0  17.919989  396.628236  4.142473  \n",
       "3    226.0  18.979527  398.564784  3.239272  \n",
       "4    234.0  18.708888  399.487766  6.115159  \n",
       "..     ...        ...         ...       ...  \n",
       "501  282.0  21.325449  395.822256  9.795056  \n",
       "502  282.0  21.032632  398.559567  9.785685  \n",
       "503  284.0  21.042043  398.026747  5.831161  \n",
       "504  275.0  21.105130  395.290366  6.890841  \n",
       "505  283.0  21.326959  400.822740  8.106447  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data, columns = ['CRIM','ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO'\n",
    " ,'B', 'LSTAT'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       True\n",
       "1      False\n",
       "2       True\n",
       "3       True\n",
       "4       True\n",
       "       ...  \n",
       "501     True\n",
       "502    False\n",
       "503     True\n",
       "504    False\n",
       "505    False\n",
       "Name: CRIM, Length: 506, dtype: bool"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CRIM'] > 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=506, step=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leave the following line untouched, it will help ensure that your \"random\" split is the same \"random\" split used by the rest of the class\n",
    "np.random.seed(seed=13579)\n",
    "\n",
    "# enter your code here\n",
    "a = np.array(df.index)\n",
    "bdata_train_idx =  np.random.choice(a, int(len(data) * .75), replace=False)\n",
    "bdata_test_idx = np.array(list(set(a) - set(list(bdata_train_idx))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>22.406867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.247928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.099452</td>\n",
       "      <td>6.199415</td>\n",
       "      <td>92.4</td>\n",
       "      <td>2.224853</td>\n",
       "      <td>24.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>20.568926</td>\n",
       "      <td>391.952694</td>\n",
       "      <td>22.798646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0.476132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.794566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.766851</td>\n",
       "      <td>6.208124</td>\n",
       "      <td>42.4</td>\n",
       "      <td>4.032132</td>\n",
       "      <td>4.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>18.819660</td>\n",
       "      <td>397.172838</td>\n",
       "      <td>9.537777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0.532648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.799418</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.802291</td>\n",
       "      <td>6.063011</td>\n",
       "      <td>53.8</td>\n",
       "      <td>4.043867</td>\n",
       "      <td>4.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>18.982791</td>\n",
       "      <td>394.249614</td>\n",
       "      <td>16.440364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.187889</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.526865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.708481</td>\n",
       "      <td>7.499923</td>\n",
       "      <td>36.6</td>\n",
       "      <td>7.572798</td>\n",
       "      <td>2.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>12.865843</td>\n",
       "      <td>355.462216</td>\n",
       "      <td>9.173969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1.741062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.780861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.664006</td>\n",
       "      <td>7.614751</td>\n",
       "      <td>90.8</td>\n",
       "      <td>2.115829</td>\n",
       "      <td>5.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>14.859422</td>\n",
       "      <td>376.320064</td>\n",
       "      <td>2.378481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.337218</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.084512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.581662</td>\n",
       "      <td>6.801661</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.403274</td>\n",
       "      <td>7.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>19.107446</td>\n",
       "      <td>397.859455</td>\n",
       "      <td>5.998552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0.512504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.580187</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.712120</td>\n",
       "      <td>6.968519</td>\n",
       "      <td>66.5</td>\n",
       "      <td>3.881264</td>\n",
       "      <td>8.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>17.698826</td>\n",
       "      <td>361.003848</td>\n",
       "      <td>8.304312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>0.579820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.728320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583601</td>\n",
       "      <td>6.519646</td>\n",
       "      <td>54.3</td>\n",
       "      <td>4.567283</td>\n",
       "      <td>5.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>19.742408</td>\n",
       "      <td>398.513612</td>\n",
       "      <td>7.516190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>16.036995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.158980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.959856</td>\n",
       "      <td>6.155798</td>\n",
       "      <td>95.4</td>\n",
       "      <td>2.000084</td>\n",
       "      <td>24.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>20.584821</td>\n",
       "      <td>7.738484</td>\n",
       "      <td>24.984607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.400492</td>\n",
       "      <td>12.5</td>\n",
       "      <td>6.307460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.755716</td>\n",
       "      <td>6.168096</td>\n",
       "      <td>33.0</td>\n",
       "      <td>6.822392</td>\n",
       "      <td>4.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>18.910360</td>\n",
       "      <td>397.204182</td>\n",
       "      <td>9.554460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>379 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          CRIM    ZN      INDUS  CHAS       NOX        RM   AGE       DIS  \\\n",
       "440  22.406867   0.0  18.247928   0.0  1.099452  6.199415  92.4  2.224853   \n",
       "215   0.476132   0.0  10.794566   0.0  0.766851  6.208124  42.4  4.032132   \n",
       "212   0.532648   0.0  10.799418   1.0  0.802291  6.063011  53.8  4.043867   \n",
       "197   0.187889  80.0   1.526865   0.0  0.708481  7.499923  36.6  7.572798   \n",
       "161   1.741062   0.0  19.780861   0.0  0.664006  7.614751  90.8  2.115829   \n",
       "..         ...   ...        ...   ...       ...       ...   ...       ...   \n",
       "250   0.337218  22.0   6.084512   0.0  0.581662  6.801661  13.0  7.403274   \n",
       "234   0.512504   0.0   6.580187   1.0  0.712120  6.968519  66.5  3.881264   \n",
       "321   0.579820   0.0   7.728320   0.0  0.583601  6.519646  54.3  4.567283   \n",
       "425  16.036995   0.0  18.158980   0.0  0.959856  6.155798  95.4  2.000084   \n",
       "69    0.400492  12.5   6.307460   0.0  0.755716  6.168096  33.0  6.822392   \n",
       "\n",
       "      RAD    TAX    PTRATIO           B      LSTAT  \n",
       "440  24.0  679.0  20.568926  391.952694  22.798646  \n",
       "215   4.0  280.0  18.819660  397.172838   9.537777  \n",
       "212   4.0  289.0  18.982791  394.249614  16.440364  \n",
       "197   2.0  334.0  12.865843  355.462216   9.173969  \n",
       "161   5.0  416.0  14.859422  376.320064   2.378481  \n",
       "..    ...    ...        ...         ...        ...  \n",
       "250   7.0  335.0  19.107446  397.859455   5.998552  \n",
       "234   8.0  320.0  17.698826  361.003848   8.304312  \n",
       "321   5.0  298.0  19.742408  398.513612   7.516190  \n",
       "425  24.0  680.0  20.584821    7.738484  24.984607  \n",
       "69    4.0  353.0  18.910360  397.204182   9.554460  \n",
       "\n",
       "[379 rows x 13 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdata_train_idx\n",
    "bdata_train = df.loc[bdata_train_idx]\n",
    "bdata_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.512354</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.904262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.743540</td>\n",
       "      <td>6.135438</td>\n",
       "      <td>85.9</td>\n",
       "      <td>6.631109</td>\n",
       "      <td>5.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>15.526087</td>\n",
       "      <td>389.794672</td>\n",
       "      <td>17.734252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.471014</td>\n",
       "      <td>12.5</td>\n",
       "      <td>8.105223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.696355</td>\n",
       "      <td>6.630284</td>\n",
       "      <td>94.3</td>\n",
       "      <td>6.559948</td>\n",
       "      <td>5.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>15.329414</td>\n",
       "      <td>394.426261</td>\n",
       "      <td>20.722270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.378099</td>\n",
       "      <td>12.5</td>\n",
       "      <td>8.037368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.733438</td>\n",
       "      <td>6.037591</td>\n",
       "      <td>82.9</td>\n",
       "      <td>6.255507</td>\n",
       "      <td>5.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>15.208535</td>\n",
       "      <td>398.942967</td>\n",
       "      <td>13.471264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.912070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.166062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.546885</td>\n",
       "      <td>5.597011</td>\n",
       "      <td>36.6</td>\n",
       "      <td>4.055867</td>\n",
       "      <td>4.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>21.232716</td>\n",
       "      <td>290.847821</td>\n",
       "      <td>12.050425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.540105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.476673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778953</td>\n",
       "      <td>5.905249</td>\n",
       "      <td>98.1</td>\n",
       "      <td>3.946739</td>\n",
       "      <td>4.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>21.224087</td>\n",
       "      <td>380.568759</td>\n",
       "      <td>21.639829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0.368150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.012763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.676803</td>\n",
       "      <td>6.060125</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.750478</td>\n",
       "      <td>6.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>19.539634</td>\n",
       "      <td>396.940713</td>\n",
       "      <td>12.058560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.636953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.906713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.602914</td>\n",
       "      <td>6.045584</td>\n",
       "      <td>42.6</td>\n",
       "      <td>2.630936</td>\n",
       "      <td>6.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>19.459740</td>\n",
       "      <td>396.919728</td>\n",
       "      <td>13.637231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.205345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.992590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.686750</td>\n",
       "      <td>6.895386</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.805111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>21.325449</td>\n",
       "      <td>395.822256</td>\n",
       "      <td>9.795056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.120722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.994115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583991</td>\n",
       "      <td>6.313574</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.652694</td>\n",
       "      <td>1.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>21.032632</td>\n",
       "      <td>398.559567</td>\n",
       "      <td>9.785685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.226099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.254201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.689092</td>\n",
       "      <td>7.199346</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.348891</td>\n",
       "      <td>1.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>21.042043</td>\n",
       "      <td>398.026747</td>\n",
       "      <td>5.831161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM    ZN      INDUS  CHAS       NOX        RM   AGE       DIS  RAD  \\\n",
       "9    0.512354  12.5   7.904262   0.0  0.743540  6.135438  85.9  6.631109  5.0   \n",
       "10   0.471014  12.5   8.105223   0.0  0.696355  6.630284  94.3  6.559948  5.0   \n",
       "11   0.378099  12.5   8.037368   0.0  0.733438  6.037591  82.9  6.255507  5.0   \n",
       "18   0.912070   0.0   8.166062   0.0  0.546885  5.597011  36.6  4.055867  4.0   \n",
       "20   1.540105   0.0   8.476673   0.0  0.778953  5.905249  98.1  3.946739  4.0   \n",
       "..        ...   ...        ...   ...       ...       ...   ...       ...  ...   \n",
       "493  0.368150   0.0  10.012763   0.0  0.676803  6.060125  54.0  2.750478  6.0   \n",
       "494  0.636953   0.0   9.906713   0.0  0.602914  6.045584  42.6  2.630936  6.0   \n",
       "501  0.205345   0.0  11.992590   0.0  0.686750  6.895386  69.1  2.805111  1.0   \n",
       "502  0.120722   0.0  11.994115   0.0  0.583991  6.313574  76.7  2.652694  1.0   \n",
       "503  0.226099   0.0  12.254201   0.0  0.689092  7.199346  91.0  2.348891  1.0   \n",
       "\n",
       "       TAX    PTRATIO           B      LSTAT  \n",
       "9    319.0  15.526087  389.794672  17.734252  \n",
       "10   318.0  15.329414  394.426261  20.722270  \n",
       "11   320.0  15.208535  398.942967  13.471264  \n",
       "18   315.0  21.232716  290.847821  12.050425  \n",
       "20   311.0  21.224087  380.568759  21.639829  \n",
       "..     ...        ...         ...        ...  \n",
       "493  401.0  19.539634  396.940713  12.058560  \n",
       "494  403.0  19.459740  396.919728  13.637231  \n",
       "501  282.0  21.325449  395.822256   9.795056  \n",
       "502  282.0  21.032632  398.559567   9.785685  \n",
       "503  284.0  21.042043  398.026747   5.831161  \n",
       "\n",
       "[127 rows x 13 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdata_test = df.loc[bdata_test_idx]\n",
    "bdata_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Use a very bad baseline for prediction, and compute RMSE\n",
    "\n",
    "Let's start by creating a very bad baseline model that predicts median home values as the averages of `MEDV` based on adjacency to Charles River. \n",
    "\n",
    "Specifically, create a model that predicts, for every observation X_i, the median home value as the average of the median home values of all houses in the **training set** that have the same adjacency value as the observation.\n",
    "\n",
    "For example - For an input observation where `CHAS==1`, the model should predict the `MEDV` as the mean of all `MEDV` values in the training set that also have `CHAS==1`.\n",
    "\n",
    "\n",
    "\n",
    "Once the model is built, do the following:\n",
    "\n",
    "1. Compute the RMSE of the training set.\n",
    "2. Now compute the RMSE of the test data set (but use the model you trained on the training set!).\n",
    "3. How does RMSE compare for training vs. testing datasets? Is this what you expected, and why?\n",
    "4. Create a scatter plot that shows the true value of each instance on the x-axis and the predicted value of each instance on the y-axis. Color the training instances in blue and the test instances in red. Make sure to label your axes appropriately, and add a legend to your figure to make clear which dots are which.\n",
    "5. Add code to your function to measure the running time of your algorithm. How long does it take to compute the predicted values for the test data?\n",
    "\n",
    "\n",
    "*NOTE - Be careful while dealing with floats and integers. Additionally, the `groupby` operation might come handy here.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = pd.DataFrame(target, columns = ['MEDV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHAS</th>\n",
       "      <th>MEDV</th>\n",
       "      <th>y_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>28.134783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>28.134783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>1.0</td>\n",
       "      <td>22.4</td>\n",
       "      <td>22.236236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.0</td>\n",
       "      <td>30.3</td>\n",
       "      <td>28.134783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>28.134783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.0</td>\n",
       "      <td>24.4</td>\n",
       "      <td>28.134783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>22.236236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23.1</td>\n",
       "      <td>28.134783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>28.134783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>28.134783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>379 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CHAS  MEDV  y_predict\n",
       "440   0.0  10.5  28.134783\n",
       "215   0.0  25.0  28.134783\n",
       "212   1.0  22.4  22.236236\n",
       "197   0.0  30.3  28.134783\n",
       "161   0.0  50.0  28.134783\n",
       "..    ...   ...        ...\n",
       "250   0.0  24.4  28.134783\n",
       "234   1.0  29.0  22.236236\n",
       "321   0.0  23.1  28.134783\n",
       "425   0.0   8.3  28.134783\n",
       "69    0.0  20.9  28.134783\n",
       "\n",
       "[379 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge target data with training data set based on index\n",
    "bdata_train_base_CR = bdata_train.merge(target_df, left_index=True, right_index=True)[['CHAS','MEDV']]\n",
    "# Baseline model with group mean as prediction\n",
    "base_model_train = bdata_train_base_CR.groupby('CHAS').agg({'MEDV': ['mean']})\n",
    "\n",
    "cas1_train = float(base_model_train.iloc[0].values)\n",
    "cas0_train = float(base_model_train.iloc[1].values)\n",
    "\n",
    "#adding a column as the y_prediction value for the test set\n",
    "bdata_train_base_CR['y_predict'] = base_model_train\n",
    "bdata_train_base_CR.loc[bdata_train_base_CR['CHAS'] == 1.0, 'y_predict'] = cas1_train\n",
    "bdata_train_base_CR.loc[bdata_train_base_CR['CHAS'] == 0.0, 'y_predict'] = cas0_train\n",
    "\n",
    "bdata_train_base_CR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute the predicted values for the test data function takes 0.002989\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "\n",
    "#merge target data with test data set based on index\n",
    "bdata_test_base_CR = bdata_test.merge(target_df, left_index= True, right_index= True)[['CHAS','MEDV']]\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "#model on test dataset\n",
    "base_model_test = bdata_test_base_CR.groupby('CHAS').agg({'MEDV': ['mean']})\n",
    "\n",
    "t1 = time()\n",
    "print('compute the predicted values for the test data function takes %f' %(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHAS</th>\n",
       "      <th>MEDV</th>\n",
       "      <th>y_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>29.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>29.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>29.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>29.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>29.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0.0</td>\n",
       "      <td>21.8</td>\n",
       "      <td>29.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.0</td>\n",
       "      <td>24.5</td>\n",
       "      <td>29.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.0</td>\n",
       "      <td>22.4</td>\n",
       "      <td>29.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20.6</td>\n",
       "      <td>29.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>29.025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CHAS  MEDV  y_predict\n",
       "9     0.0  18.9     29.025\n",
       "10    0.0  15.0     29.025\n",
       "11    0.0  18.9     29.025\n",
       "18    0.0  20.2     29.025\n",
       "20    0.0  13.6     29.025\n",
       "..    ...   ...        ...\n",
       "493   0.0  21.8     29.025\n",
       "494   0.0  24.5     29.025\n",
       "501   0.0  22.4     29.025\n",
       "502   0.0  20.6     29.025\n",
       "503   0.0  23.9     29.025\n",
       "\n",
       "[127 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting the y_predict value for each CHAS value\n",
    "cas1_test = float(base_model_test.iloc[0].values)\n",
    "cas0_test = float(base_model_test.iloc[1].values)\n",
    "\n",
    "#adding a column as the y_prediction value for the test set\n",
    "bdata_test_base_CR['y_predict'] = base_model_test\n",
    "bdata_test_base_CR.loc[bdata_test_base_CR['CHAS'] == 1.0, 'y_predict'] = cas1_test\n",
    "bdata_test_base_CR.loc[bdata_test_base_CR['CHAS'] == 0.0, 'y_predict'] = cas0_test\n",
    "\n",
    "bdata_test_base_CR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.73014468436032"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate the RMSE for the training data based on y_training and y_prediction(mean)\n",
    "train_predictions = bdata_train_base_CR['y_predict']\n",
    "train_yvalues = bdata_train_base_CR['MEDV']\n",
    "compute_rmse(train_predictions, train_yvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.845547450978923"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calulate the RMSE for the test data based on y_prediction(mean) and y_test\n",
    "test_predictions = bdata_test_base_CR['y_predict']\n",
    "test_yvalues = bdata_test_base_CR['MEDV']\n",
    "compute_rmse(test_predictions, test_yvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does RMSE compare for training vs. testing datasets? Is this what you expected, and why?\n",
    "- The test RMSE is lower than the train dataset RMSE. It is what I expected because the data entries for the test dataset is less than the traning set; therefore the variance for the test dataset is lower, which can be the effect of a lower RMSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Predict Value')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create a scatter plot that shows the true value of each instance on the x-axis and the predicted value of each instance on the y-axis. Color the training instances in blue and the test instances in red. Make sure to label your axes appropriately, and add a legend to your figure to make clear which dots are which.\n",
    "plt.scatter(bdata_train_base_CR.MEDV, bdata_train_base_CR.y_predict,  c='b', label='Training set')\n",
    "plt.scatter(bdata_test_base_CR.MEDV, bdata_test_base_CR.y_predict, c='r', label='Test set')\n",
    "plt.legend()\n",
    "plt.title('predict value versus true value')\n",
    "plt.xlabel('True Value')\n",
    "plt.ylabel('Predict Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute the predicted values for the test data function takes 0.002989\n"
     ]
    }
   ],
   "source": [
    "print('compute the predicted values for the test data function takes %f' %(t1-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to compute the predicted values for the test data?\n",
    "- compute the predicted values for the test data function takes around 0.0029"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Nearest Neighbors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Nearest Neighbors: Distance function\n",
    "Let's try and build a machine learning algorithm to beat the \"Average Value\" baseline that you computed above.  Soon you will implement the Nearest Neighbor algorithm, but first you need to create a distance metric to measure the distance (and similarity) between two instances.  Write a generic function to compute the L-Norm distance (called the [*p*-norm][1] distance on Wikipedia). Verify that your function works by computing the Euclidean distance between the points (1,2) and (1,8), and then compute the Manhattan distance between (4,4) and (12,10).\n",
    "\n",
    "[1]: https://en.wikipedia.org/wiki/Norm_(mathematics)#p-norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "distance\n",
    "\n",
    "Given two instances and a value for L, return the L-Norm distance between them\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "x1, x2 : array\n",
    "    Array of numerical values corresponding to predictions for each of the N observations\n",
    "\n",
    "L: int\n",
    "    Value of L to use in computing distances\n",
    "\n",
    "Returns\n",
    "-------\n",
    "dist : int\n",
    "    The L-norm distance between instances\n",
    "\n",
    "Example\n",
    "-------\n",
    ">>> print(distance((1,2),(1,8),2))\n",
    "6\n",
    "\n",
    "\n",
    "def distance(x1, x2, L):\n",
    "    #array of y\n",
    "    p = np.array([x1[1], x2[1]])\n",
    "    #array of x\n",
    "    q = np.array([x1[0], x2[0]])\n",
    "    \n",
    "    if L == 1:\n",
    "\n",
    "        return np.sum(np.absolute(p -q))\n",
    "    if L == 2:\n",
    "        print(p,q)\n",
    "        return np.sqrt(np.sum(p - q)**2)\n",
    "\"\"\"\n",
    "\n",
    "    \n",
    "def distance(x1, x2, L):\n",
    "    p1 = np.array(x1)\n",
    "    q1 = np.array(x2)\n",
    "    diff = q1 - p1\n",
    "    \n",
    "    if L == 1:\n",
    "        return np.sum(np.absolute(diff))\n",
    "    if L == 2:\n",
    "        return np.sqrt(np.sum(diff)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n"
     ]
    }
   ],
   "source": [
    "#test run\n",
    "print(distance(([1,0,0],[2,0,7]),([1,0,9],[8,0,0]),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Basic Nearest Neighbor algorithm\n",
    "\n",
    "Your next task is to implement a basic nearest neighbor algorithm from scratch.  Your simple model will use three input features (`CRIM, RM and ZN`) and a single output (`MEDV`).  In other words, you are modelling the relationship between median home value and crime rates, house size and the proportion of residential land zoned for lots.\n",
    "\n",
    "Use your training data (bdata_train) to \"fit\" your model, although as you know, with Nearest Neighbors there is no real training, you just need to keep your training data in memory.  Write a function that predicts the median home value using the nearest neighbor algorithm we discussed in class.  Since this is a small dataset, you can simply compare your test instance to every instance in the training set, and return the `MEDV` value of the closest training instance.  Have your function take L as an input, where L is passed to the distance function. Use L=2 for all questions henceforth unless explicitly stated otherwise.\n",
    "\n",
    "Make sure to do the following - \n",
    "1. Fill in the function specification below\n",
    "2. Use your algorithm to predict the median home value of every instance in the test set. Report the RMSE (\"test RMSE\")\n",
    "3. Use your algorithm to predict the median home value of every instance in the training set and report the training RMSE.\n",
    "4. Create a scatter plot that shows the true value of each instance on the x-axis and the predicted value of each instance on the y-axis. Color the training instances in blue and the test instances in red. \n",
    "5. Report an estimate of the total time taken by your code to predict the nearest neighbors for all the values in the test data set.\n",
    "6. How does the performance (test RMSE and total runtime) of your nearest neighbors algorithm compare to the baseline in part 1.3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>RM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>22.406867</td>\n",
       "      <td>6.199415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0.476132</td>\n",
       "      <td>6.208124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0.532648</td>\n",
       "      <td>6.063011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.187889</td>\n",
       "      <td>7.499923</td>\n",
       "      <td>80.0</td>\n",
       "      <td>30.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1.741062</td>\n",
       "      <td>7.614751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.337218</td>\n",
       "      <td>6.801661</td>\n",
       "      <td>22.0</td>\n",
       "      <td>24.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0.512504</td>\n",
       "      <td>6.968519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>0.579820</td>\n",
       "      <td>6.519646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>16.036995</td>\n",
       "      <td>6.155798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.400492</td>\n",
       "      <td>6.168096</td>\n",
       "      <td>12.5</td>\n",
       "      <td>20.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>379 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          CRIM        RM    ZN  MEDV\n",
       "440  22.406867  6.199415   0.0  10.5\n",
       "215   0.476132  6.208124   0.0  25.0\n",
       "212   0.532648  6.063011   0.0  22.4\n",
       "197   0.187889  7.499923  80.0  30.3\n",
       "161   1.741062  7.614751   0.0  50.0\n",
       "..         ...       ...   ...   ...\n",
       "250   0.337218  6.801661  22.0  24.4\n",
       "234   0.512504  6.968519   0.0  29.0\n",
       "321   0.579820  6.519646   0.0  23.1\n",
       "425  16.036995  6.155798   0.0   8.3\n",
       "69    0.400492  6.168096  12.5  20.9\n",
       "\n",
       "[379 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basicNN_train_df = bdata_train[['CRIM','RM','ZN']].merge(target_df, left_index= True, right_index= True)\n",
    "basicNN_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>RM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.512354</td>\n",
       "      <td>6.135438</td>\n",
       "      <td>12.5</td>\n",
       "      <td>18.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.471014</td>\n",
       "      <td>6.630284</td>\n",
       "      <td>12.5</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.378099</td>\n",
       "      <td>6.037591</td>\n",
       "      <td>12.5</td>\n",
       "      <td>18.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.912070</td>\n",
       "      <td>5.597011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.540105</td>\n",
       "      <td>5.905249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0.368150</td>\n",
       "      <td>6.060125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.636953</td>\n",
       "      <td>6.045584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.205345</td>\n",
       "      <td>6.895386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.120722</td>\n",
       "      <td>6.313574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.226099</td>\n",
       "      <td>7.199346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM        RM    ZN  MEDV\n",
       "9    0.512354  6.135438  12.5  18.9\n",
       "10   0.471014  6.630284  12.5  15.0\n",
       "11   0.378099  6.037591  12.5  18.9\n",
       "18   0.912070  5.597011   0.0  20.2\n",
       "20   1.540105  5.905249   0.0  13.6\n",
       "..        ...       ...   ...   ...\n",
       "493  0.368150  6.060125   0.0  21.8\n",
       "494  0.636953  6.045584   0.0  24.5\n",
       "501  0.205345  6.895386   0.0  22.4\n",
       "502  0.120722  6.313574   0.0  20.6\n",
       "503  0.226099  7.199346   0.0  23.9\n",
       "\n",
       "[127 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basicNN_test_df = bdata_test[['CRIM','RM','ZN']].merge(target_df, left_index= True, right_index= True)\n",
    "basicNN_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "basicNN_df = pd.concat([basicNN_train_df, basicNN_test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test RMSE | train RMSW\n",
      "Time taken: 5.52 seconds\n",
      "(11.4933428180777, 11.501627738422306)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "Nearest Neighbors\n",
    "\n",
    "Implementation of nearest neighbors algorithm.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "x_train: array\n",
    "    Array of numerical feature values for training the model.\n",
    "y_train: array\n",
    "    Array of numerical output values for training the model.\n",
    "x_test: array\n",
    "    Array of numerical feature values for testing the model.\n",
    "y_test: array\n",
    "    Array of numerical output values for testing the model.\n",
    "L: int\n",
    "    Order of L-norm function used for calculating distance.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "rmse : int\n",
    "    Value of the RMSE from data.\n",
    "\"\"\"\n",
    "\n",
    "import time \n",
    "    \n",
    "    \n",
    "#nneighbor for the trainning set\n",
    "def nneighbortrain(x_train,y_train, x_test,y_test, L):\n",
    "    #create a list for predict value\n",
    "    predict_test = []\n",
    "\n",
    "    for i in range (len(x_train)):\n",
    "\n",
    "        #create new train set for compare\n",
    "        curr_x_train = x_train.drop(x_train.copy().index[i])\n",
    "\n",
    "        #get the test set value\n",
    "        test_row_train = x_train.iloc[i].values\n",
    "\n",
    "        #compare test set value with whole training set\n",
    "        diff_fun_train = curr_x_train.apply(lambda row: distance(row, test_row_train, L), axis = 1)\n",
    "\n",
    "        #get the index of the value\n",
    "        idx = diff_fun_train[diff_fun_train == min(diff_fun_train)].index[0]\n",
    "\n",
    "        #create a new predict value and append it to the list\n",
    "        y_predict_train = y_train.loc[idx]\n",
    "        predict_test.append(y_predict_train)\n",
    "\n",
    "\n",
    "    rmse = compute_rmse(predict_test, y_train)\n",
    "\n",
    "    return rmse, predict_test\n",
    "    \n",
    "#nneighbor for the test set     \n",
    "def nneighbortest(x_train,y_train, x_test, y_test, L):\n",
    "    #create a list for predict value\n",
    "    predict_test = []\n",
    "\n",
    "    for i in range (len(x_test)):\n",
    "\n",
    "        #get the test set value\n",
    "        test_row = x_test.iloc[i].values\n",
    "\n",
    "        #compare test set value with whole training set\n",
    "        diff_fun = x_train.apply(lambda row: distance(row, test_row, L), axis = 1)\n",
    "\n",
    "        #get the index of the value\n",
    "        idx = diff_fun[diff_fun == min(diff_fun)].index[0]\n",
    "\n",
    "        #create a new predict value and append to the list\n",
    "        y_predict_test = y_train.loc[idx]\n",
    "        predict_test.append(y_predict_test)\n",
    "        \n",
    "    rmse = compute_rmse(predict_test, y_test)\n",
    "\n",
    "    return rmse, predict_test\n",
    "    \n",
    "##plot graph function   \n",
    "def plotgraph(x_train,y_train, x_test,y_test,L):\n",
    "    y_predict_train = nneighbortrain(x_train,y_train, x_test,y_test, L)[1]\n",
    "    y_predict_test = nneighbortest(x_train,y_train, x_test,y_test, L)[1]\n",
    "    \n",
    "    #Create a scatter plot that shows the true value of each instance on the x-axis and the predicted value of each instance on the y-axis. Color the training instances in blue and the test instances in red. Make sure to label your axes appropriately, and add a legend to your figure to make clear which dots are which.\n",
    "    plt.scatter(y_train, y_predict_train, c='b', label='Train set')\n",
    "    plt.scatter(y_test, y_predict_test,  c='r', label='Test set')\n",
    "    plt.legend()\n",
    "    plt.title('predict value versus true value')\n",
    "    plt.xlabel('True Value')\n",
    "    plt.ylabel('Predict Value')\n",
    "    \n",
    "\n",
    "#The nneighbor function    \n",
    "def nneighbor(x_train,y_train, x_test,y_test, L):\n",
    "    start_time = time.time()\n",
    "    #your code here\n",
    "    \n",
    "    r_train = nneighbortrain(x_train,y_train, x_test,y_test, L)[0]\n",
    "    r_test = nneighbortest(x_train,y_train, x_test,y_test, L)[0]\n",
    "    \n",
    "    \n",
    "    rmse = (r_test,r_train)\n",
    "    \n",
    "    print(\"Time taken: {:.2f} seconds\".format(time.time() - start_time))\n",
    "    return rmse\n",
    "    \n",
    "#drive code\n",
    "x_train = basicNN_train_df[['CRIM', 'RM', 'ZN']]\n",
    "y_train = basicNN_train_df['MEDV']\n",
    "x_test = basicNN_test_df[['CRIM', 'RM', 'ZN']]\n",
    "y_test = basicNN_test_df['MEDV']\n",
    "\n",
    "\n",
    "print(nneighbor(x_train,y_train, x_test,y_test, 2))\n",
    "plotgraph(x_train,y_train, x_test,y_test,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report an estimate of the total time taken by your code to predict the nearest neighbors for all the values in the test data set.\n",
    "- Total time is around 5.5 seconds. \n",
    "- Test set RMSE is 11.49; Train set RMSE is 11.50.\n",
    "\n",
    "How does the performance (test RMSE and total runtime) of your nearest neighbors algorithm compare to the baseline in part 1.3?\n",
    "- Much longer run time compairing to the base line is 0.0029; the RMSE for train set is not as accurate as the baseline model, the test set model improved slightly compare to the baseline model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Results and Normalization\n",
    "\n",
    "If you were being astute, you would have noticed that we never normalized our features -- a big no-no with Nearest Neighbor algorithms.  Write a generic normalization function that takes as input an array of values for a given feature, and returns the standardized array (subtract the mean and divide by the standard deviation).\n",
    "\n",
    "Re-run the Nearest Neighbor algorithm on the normalized dataset (still just using `CRIM, RM and ZN` as input), and compare the RMSE from this method with your previous RMSE evaluations. What do you observe?\n",
    "\n",
    "*NOTE*: To normalize properly, you should compute the mean and standard deviation on the training set, and use the same values to normalize both the training and the testing dataset.\n",
    "\n",
    "*NOTE 2*: In this case, the normalization may or may not reduce the RMSE; don't get confused if you find that to be the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "Normalize data\n",
    "\n",
    "Normalize all of the features in a data frame.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "raw_data: array\n",
    "    Array of numerical values to normalize.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "normalized_data : array\n",
    "    The array with normalized values for all features\n",
    "\"\"\"\n",
    "def normalize(raw_data):\n",
    "\n",
    "    np_data = np.array(raw_data)\n",
    "    mean = np.sum(np_data)/len(np_data)\n",
    "    D = np.sum((np_data - mean)**2)/len(np_data)\n",
    "    SD = np.sqrt(D)\n",
    "\n",
    "    normalized_data = (np_data - mean)/SD\n",
    "    \n",
    "    # if we only passed 1 array then need to return the sd and mean to calculate the test set based on the training set as well!\n",
    "    return normalized_data, SD, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRIM SD: 7.640904439758599 CRIM mean: 3.576281393332291\n",
      "RM SD: 0.7218807684668589 RM mean: 6.474501995263727\n",
      "ZN SD: 23.57496969353867 ZN mean: 11.655672823218998\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>RM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>MEDV</th>\n",
       "      <th>CRIM_opt</th>\n",
       "      <th>RM_opt</th>\n",
       "      <th>ZN_opt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>22.406867</td>\n",
       "      <td>6.199415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>2.464445</td>\n",
       "      <td>-0.381070</td>\n",
       "      <td>-0.494409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0.476132</td>\n",
       "      <td>6.208124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-0.405731</td>\n",
       "      <td>-0.369005</td>\n",
       "      <td>-0.494409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0.532648</td>\n",
       "      <td>6.063011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.4</td>\n",
       "      <td>-0.398334</td>\n",
       "      <td>-0.570027</td>\n",
       "      <td>-0.494409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.187889</td>\n",
       "      <td>7.499923</td>\n",
       "      <td>80.0</td>\n",
       "      <td>30.3</td>\n",
       "      <td>-0.443454</td>\n",
       "      <td>1.420486</td>\n",
       "      <td>2.899021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1.741062</td>\n",
       "      <td>7.614751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-0.240184</td>\n",
       "      <td>1.579553</td>\n",
       "      <td>-0.494409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.337218</td>\n",
       "      <td>6.801661</td>\n",
       "      <td>22.0</td>\n",
       "      <td>24.4</td>\n",
       "      <td>-0.423911</td>\n",
       "      <td>0.453204</td>\n",
       "      <td>0.438784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0.512504</td>\n",
       "      <td>6.968519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-0.400970</td>\n",
       "      <td>0.684348</td>\n",
       "      <td>-0.494409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>0.579820</td>\n",
       "      <td>6.519646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.1</td>\n",
       "      <td>-0.392161</td>\n",
       "      <td>0.062537</td>\n",
       "      <td>-0.494409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>16.036995</td>\n",
       "      <td>6.155798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1.630790</td>\n",
       "      <td>-0.441491</td>\n",
       "      <td>-0.494409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.400492</td>\n",
       "      <td>6.168096</td>\n",
       "      <td>12.5</td>\n",
       "      <td>20.9</td>\n",
       "      <td>-0.415630</td>\n",
       "      <td>-0.424455</td>\n",
       "      <td>0.035815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>379 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          CRIM        RM    ZN  MEDV  CRIM_opt    RM_opt    ZN_opt\n",
       "440  22.406867  6.199415   0.0  10.5  2.464445 -0.381070 -0.494409\n",
       "215   0.476132  6.208124   0.0  25.0 -0.405731 -0.369005 -0.494409\n",
       "212   0.532648  6.063011   0.0  22.4 -0.398334 -0.570027 -0.494409\n",
       "197   0.187889  7.499923  80.0  30.3 -0.443454  1.420486  2.899021\n",
       "161   1.741062  7.614751   0.0  50.0 -0.240184  1.579553 -0.494409\n",
       "..         ...       ...   ...   ...       ...       ...       ...\n",
       "250   0.337218  6.801661  22.0  24.4 -0.423911  0.453204  0.438784\n",
       "234   0.512504  6.968519   0.0  29.0 -0.400970  0.684348 -0.494409\n",
       "321   0.579820  6.519646   0.0  23.1 -0.392161  0.062537 -0.494409\n",
       "425  16.036995  6.155798   0.0   8.3  1.630790 -0.441491 -0.494409\n",
       "69    0.400492  6.168096  12.5  20.9 -0.415630 -0.424455  0.035815\n",
       "\n",
       "[379 rows x 7 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create new df copy with the updated standardized value and report the SD and mean value for each feature\n",
    "optNN_train_df = bdata_train[['CRIM','RM','ZN']].merge(target_df, left_index= True, right_index= True)\n",
    "\n",
    "raw_CRIM = normalize(optNN_train_df['CRIM'])\n",
    "optNN_train_df['CRIM_opt'] = raw_CRIM[0] \n",
    "print('CRIM SD: ' + str(raw_CRIM[1]) + ' CRIM mean: ' + str(raw_CRIM[2]))\n",
    "\n",
    "raw_RM = normalize(optNN_train_df['RM'])\n",
    "optNN_train_df['RM_opt'] = raw_RM[0]\n",
    "print('RM SD: ' + str(raw_RM[1]) + ' RM mean: ' + str(raw_RM[2]))\n",
    "\n",
    "raw_ZN = normalize(optNN_train_df['ZN'])\n",
    "optNN_train_df['ZN_opt'] = raw_ZN[0]\n",
    "print('ZN SD: ' + str(raw_ZN[1]) + ' ZN mean: '+ str(raw_ZN[2]))\n",
    "\n",
    "optNN_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>RM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>MEDV</th>\n",
       "      <th>CRIM_opt</th>\n",
       "      <th>RM_opt</th>\n",
       "      <th>ZN_opt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.512354</td>\n",
       "      <td>6.135438</td>\n",
       "      <td>12.5</td>\n",
       "      <td>18.9</td>\n",
       "      <td>-0.400990</td>\n",
       "      <td>-0.469696</td>\n",
       "      <td>0.035815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.471014</td>\n",
       "      <td>6.630284</td>\n",
       "      <td>12.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.406400</td>\n",
       "      <td>0.215800</td>\n",
       "      <td>0.035815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.378099</td>\n",
       "      <td>6.037591</td>\n",
       "      <td>12.5</td>\n",
       "      <td>18.9</td>\n",
       "      <td>-0.418561</td>\n",
       "      <td>-0.605240</td>\n",
       "      <td>0.035815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.912070</td>\n",
       "      <td>5.597011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>-0.348678</td>\n",
       "      <td>-1.215562</td>\n",
       "      <td>-0.494409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.540105</td>\n",
       "      <td>5.905249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>-0.266484</td>\n",
       "      <td>-0.788570</td>\n",
       "      <td>-0.494409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0.368150</td>\n",
       "      <td>6.060125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.8</td>\n",
       "      <td>-0.419863</td>\n",
       "      <td>-0.574025</td>\n",
       "      <td>-0.494409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.636953</td>\n",
       "      <td>6.045584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.5</td>\n",
       "      <td>-0.384683</td>\n",
       "      <td>-0.594168</td>\n",
       "      <td>-0.494409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.205345</td>\n",
       "      <td>6.895386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.4</td>\n",
       "      <td>-0.441170</td>\n",
       "      <td>0.583038</td>\n",
       "      <td>-0.494409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.120722</td>\n",
       "      <td>6.313574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.6</td>\n",
       "      <td>-0.452245</td>\n",
       "      <td>-0.222929</td>\n",
       "      <td>-0.494409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.226099</td>\n",
       "      <td>7.199346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>-0.438454</td>\n",
       "      <td>1.004105</td>\n",
       "      <td>-0.494409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM        RM    ZN  MEDV  CRIM_opt    RM_opt    ZN_opt\n",
       "9    0.512354  6.135438  12.5  18.9 -0.400990 -0.469696  0.035815\n",
       "10   0.471014  6.630284  12.5  15.0 -0.406400  0.215800  0.035815\n",
       "11   0.378099  6.037591  12.5  18.9 -0.418561 -0.605240  0.035815\n",
       "18   0.912070  5.597011   0.0  20.2 -0.348678 -1.215562 -0.494409\n",
       "20   1.540105  5.905249   0.0  13.6 -0.266484 -0.788570 -0.494409\n",
       "..        ...       ...   ...   ...       ...       ...       ...\n",
       "493  0.368150  6.060125   0.0  21.8 -0.419863 -0.574025 -0.494409\n",
       "494  0.636953  6.045584   0.0  24.5 -0.384683 -0.594168 -0.494409\n",
       "501  0.205345  6.895386   0.0  22.4 -0.441170  0.583038 -0.494409\n",
       "502  0.120722  6.313574   0.0  20.6 -0.452245 -0.222929 -0.494409\n",
       "503  0.226099  7.199346   0.0  23.9 -0.438454  1.004105 -0.494409\n",
       "\n",
       "[127 rows x 7 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CRIM_SD = 7.640904439758599 \n",
    "CRIM_mean = 3.576281393332291\n",
    "RM_SD = 0.7218807684668589 \n",
    "RM_mean = 6.474501995263727\n",
    "ZN_SD = 23.57496969353867 \n",
    "ZN_mean = 11.655672823218998\n",
    "\n",
    "#use the train set SD and mean value for the standadization\n",
    "def normalize_test(raw_data, SD, mean):\n",
    "    #your code here\n",
    "    np_data = np.array(raw_data)\n",
    "    normalized_data_test = (np_data - mean)/SD\n",
    "    \n",
    "    return normalized_data_test\n",
    "\n",
    "\n",
    "optNN_test_df = bdata_test[['CRIM','RM','ZN']].merge(target_df, left_index= True, right_index= True)\n",
    "\n",
    "raw_CRIM_test = normalize_test(optNN_test_df['CRIM'],CRIM_SD,CRIM_mean)\n",
    "optNN_test_df['CRIM_opt'] = raw_CRIM_test\n",
    "\n",
    "raw_RM_test = normalize_test(optNN_test_df['RM'],RM_SD,RM_mean)\n",
    "optNN_test_df['RM_opt'] = raw_RM_test \n",
    "\n",
    "raw_ZN_test = normalize_test(optNN_test_df['ZN'],ZN_SD, ZN_mean)\n",
    "optNN_test_df['ZN_opt'] = raw_ZN_test\n",
    "\n",
    "optNN_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12062\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "C:\\Users\\12062\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 5.02 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12.783496989305803, 11.207480775348905)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use the standadized value to calculate the nn value\n",
    "opt_x_train = optNN_train_df[['CRIM_opt', 'RM_opt', 'ZN_opt']]\n",
    "opt_y_train = optNN_train_df['MEDV']\n",
    "\n",
    "opt_x_test = optNN_test_df[['CRIM_opt', 'RM_opt', 'ZN_opt']]\n",
    "opt_y_test = optNN_test_df['MEDV']\n",
    "nneighbor(opt_x_train,opt_y_train, opt_x_test,opt_y_test, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the test set RMSE is wose but the training set is improved. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Optimization\n",
    "\n",
    "A lot of the decisions we've made so far have been arbitrary.  Try to increase the performance of your nearest neighbor algorithm by adding features that you think might be relevant, and by using different values of L in the distance function.  Try a model that uses a different set of 2 features, then try at least one model that uses more than 4 features, then try using a different value of L.  If you're having fun, try a few different combinations of features and L! Use the test set to report the RMSE values.\n",
    "\n",
    "What combination of features and distance function provide the lowest RMSE on the test set?  Do your decisions affect the running time of the algorithm?\n",
    "\n",
    "*NOTE:* For this and all subsequent questions, you should use normalized features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = bdata_train.merge(target_df, left_index= True, right_index= True)\n",
    "test = bdata_test.merge(target_df, left_index= True, right_index= True)\n",
    "\n",
    "x_train = train.loc[:, train.columns != 'MEDV']\n",
    "x_test = test.loc[:, test.columns != 'MEDV']\n",
    "y_train = train.loc[:, train.columns == 'MEDV']\n",
    "y_test = test.loc[:, test.columns == 'MEDV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>22.406867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.247928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.099452</td>\n",
       "      <td>6.199415</td>\n",
       "      <td>92.4</td>\n",
       "      <td>2.224853</td>\n",
       "      <td>24.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>20.568926</td>\n",
       "      <td>391.952694</td>\n",
       "      <td>22.798646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0.476132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.794566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.766851</td>\n",
       "      <td>6.208124</td>\n",
       "      <td>42.4</td>\n",
       "      <td>4.032132</td>\n",
       "      <td>4.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>18.819660</td>\n",
       "      <td>397.172838</td>\n",
       "      <td>9.537777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0.532648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.799418</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.802291</td>\n",
       "      <td>6.063011</td>\n",
       "      <td>53.8</td>\n",
       "      <td>4.043867</td>\n",
       "      <td>4.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>18.982791</td>\n",
       "      <td>394.249614</td>\n",
       "      <td>16.440364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.187889</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.526865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.708481</td>\n",
       "      <td>7.499923</td>\n",
       "      <td>36.6</td>\n",
       "      <td>7.572798</td>\n",
       "      <td>2.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>12.865843</td>\n",
       "      <td>355.462216</td>\n",
       "      <td>9.173969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1.741062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.780861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.664006</td>\n",
       "      <td>7.614751</td>\n",
       "      <td>90.8</td>\n",
       "      <td>2.115829</td>\n",
       "      <td>5.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>14.859422</td>\n",
       "      <td>376.320064</td>\n",
       "      <td>2.378481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.337218</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.084512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.581662</td>\n",
       "      <td>6.801661</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.403274</td>\n",
       "      <td>7.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>19.107446</td>\n",
       "      <td>397.859455</td>\n",
       "      <td>5.998552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0.512504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.580187</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.712120</td>\n",
       "      <td>6.968519</td>\n",
       "      <td>66.5</td>\n",
       "      <td>3.881264</td>\n",
       "      <td>8.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>17.698826</td>\n",
       "      <td>361.003848</td>\n",
       "      <td>8.304312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>0.579820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.728320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583601</td>\n",
       "      <td>6.519646</td>\n",
       "      <td>54.3</td>\n",
       "      <td>4.567283</td>\n",
       "      <td>5.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>19.742408</td>\n",
       "      <td>398.513612</td>\n",
       "      <td>7.516190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>16.036995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.158980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.959856</td>\n",
       "      <td>6.155798</td>\n",
       "      <td>95.4</td>\n",
       "      <td>2.000084</td>\n",
       "      <td>24.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>20.584821</td>\n",
       "      <td>7.738484</td>\n",
       "      <td>24.984607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.400492</td>\n",
       "      <td>12.5</td>\n",
       "      <td>6.307460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.755716</td>\n",
       "      <td>6.168096</td>\n",
       "      <td>33.0</td>\n",
       "      <td>6.822392</td>\n",
       "      <td>4.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>18.910360</td>\n",
       "      <td>397.204182</td>\n",
       "      <td>9.554460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>379 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          CRIM    ZN      INDUS  CHAS       NOX        RM   AGE       DIS  \\\n",
       "440  22.406867   0.0  18.247928   0.0  1.099452  6.199415  92.4  2.224853   \n",
       "215   0.476132   0.0  10.794566   0.0  0.766851  6.208124  42.4  4.032132   \n",
       "212   0.532648   0.0  10.799418   1.0  0.802291  6.063011  53.8  4.043867   \n",
       "197   0.187889  80.0   1.526865   0.0  0.708481  7.499923  36.6  7.572798   \n",
       "161   1.741062   0.0  19.780861   0.0  0.664006  7.614751  90.8  2.115829   \n",
       "..         ...   ...        ...   ...       ...       ...   ...       ...   \n",
       "250   0.337218  22.0   6.084512   0.0  0.581662  6.801661  13.0  7.403274   \n",
       "234   0.512504   0.0   6.580187   1.0  0.712120  6.968519  66.5  3.881264   \n",
       "321   0.579820   0.0   7.728320   0.0  0.583601  6.519646  54.3  4.567283   \n",
       "425  16.036995   0.0  18.158980   0.0  0.959856  6.155798  95.4  2.000084   \n",
       "69    0.400492  12.5   6.307460   0.0  0.755716  6.168096  33.0  6.822392   \n",
       "\n",
       "      RAD    TAX    PTRATIO           B      LSTAT  \n",
       "440  24.0  679.0  20.568926  391.952694  22.798646  \n",
       "215   4.0  280.0  18.819660  397.172838   9.537777  \n",
       "212   4.0  289.0  18.982791  394.249614  16.440364  \n",
       "197   2.0  334.0  12.865843  355.462216   9.173969  \n",
       "161   5.0  416.0  14.859422  376.320064   2.378481  \n",
       "..    ...    ...        ...         ...        ...  \n",
       "250   7.0  335.0  19.107446  397.859455   5.998552  \n",
       "234   8.0  320.0  17.698826  361.003848   8.304312  \n",
       "321   5.0  298.0  19.742408  398.513612   7.516190  \n",
       "425  24.0  680.0  20.584821    7.738484  24.984607  \n",
       "69    4.0  353.0  18.910360  397.204182   9.554460  \n",
       "\n",
       "[379 rows x 13 columns]"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new normalize function that takes in both dataframe and return the optimized dataframe \n",
    "def normalize_df(train_data, test_data):\n",
    "    norm_train_data = train_data.copy()\n",
    "    #your code here\n",
    "    std = train_data.std(axis = 0)\n",
    "    mean = train_data.mean(axis = 0)\n",
    "    norm_train_data = norm_train_data.sub(mean, axis='columns')\n",
    "    norm_train_data = norm_train_data.div(std, axis='columns')\n",
    "    \n",
    "    norm_test_data = test_data.copy()\n",
    "    norm_test_data = norm_test_data.sub(mean, axis='columns')\n",
    "    norm_test_data = norm_test_data.div(std, axis='columns')    \n",
    "    \n",
    "    return norm_train_data, norm_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = normalize_df(x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>2.461191</td>\n",
       "      <td>-0.493756</td>\n",
       "      <td>1.043701</td>\n",
       "      <td>-0.253843</td>\n",
       "      <td>2.176443</td>\n",
       "      <td>-0.380567</td>\n",
       "      <td>0.883710</td>\n",
       "      <td>-0.874098</td>\n",
       "      <td>1.739447</td>\n",
       "      <td>1.620964</td>\n",
       "      <td>0.895841</td>\n",
       "      <td>0.372297</td>\n",
       "      <td>1.380542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>-0.405195</td>\n",
       "      <td>-0.493756</td>\n",
       "      <td>-0.047764</td>\n",
       "      <td>-0.253843</td>\n",
       "      <td>0.142332</td>\n",
       "      <td>-0.368518</td>\n",
       "      <td>-0.852630</td>\n",
       "      <td>-0.040545</td>\n",
       "      <td>-0.609147</td>\n",
       "      <td>-0.780021</td>\n",
       "      <td>0.080206</td>\n",
       "      <td>0.426898</td>\n",
       "      <td>-0.468251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>-0.397808</td>\n",
       "      <td>-0.493756</td>\n",
       "      <td>-0.047053</td>\n",
       "      <td>3.929048</td>\n",
       "      <td>0.359076</td>\n",
       "      <td>-0.569274</td>\n",
       "      <td>-0.456745</td>\n",
       "      <td>-0.035133</td>\n",
       "      <td>-0.609147</td>\n",
       "      <td>-0.725864</td>\n",
       "      <td>0.156269</td>\n",
       "      <td>0.396322</td>\n",
       "      <td>0.494088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>-0.442869</td>\n",
       "      <td>2.895194</td>\n",
       "      <td>-1.404919</td>\n",
       "      <td>-0.253843</td>\n",
       "      <td>-0.214641</td>\n",
       "      <td>1.418611</td>\n",
       "      <td>-1.054046</td>\n",
       "      <td>1.592479</td>\n",
       "      <td>-0.844007</td>\n",
       "      <td>-0.455076</td>\n",
       "      <td>-2.695897</td>\n",
       "      <td>-0.009380</td>\n",
       "      <td>-0.518972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>-0.239866</td>\n",
       "      <td>-0.493756</td>\n",
       "      <td>1.268183</td>\n",
       "      <td>-0.253843</td>\n",
       "      <td>-0.486640</td>\n",
       "      <td>1.577468</td>\n",
       "      <td>0.828147</td>\n",
       "      <td>-0.924382</td>\n",
       "      <td>-0.491717</td>\n",
       "      <td>0.038360</td>\n",
       "      <td>-1.766346</td>\n",
       "      <td>0.208786</td>\n",
       "      <td>-1.466380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>-0.423351</td>\n",
       "      <td>0.438205</td>\n",
       "      <td>-0.737501</td>\n",
       "      <td>-0.253843</td>\n",
       "      <td>-0.990238</td>\n",
       "      <td>0.452606</td>\n",
       "      <td>-1.873599</td>\n",
       "      <td>1.514291</td>\n",
       "      <td>-0.256858</td>\n",
       "      <td>-0.449058</td>\n",
       "      <td>0.214392</td>\n",
       "      <td>0.434080</td>\n",
       "      <td>-0.961680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>-0.400441</td>\n",
       "      <td>-0.493756</td>\n",
       "      <td>-0.664914</td>\n",
       "      <td>3.929048</td>\n",
       "      <td>-0.192388</td>\n",
       "      <td>0.683444</td>\n",
       "      <td>-0.015714</td>\n",
       "      <td>-0.110129</td>\n",
       "      <td>-0.139428</td>\n",
       "      <td>-0.539321</td>\n",
       "      <td>-0.442409</td>\n",
       "      <td>0.048583</td>\n",
       "      <td>-0.640217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>-0.391643</td>\n",
       "      <td>-0.493756</td>\n",
       "      <td>-0.496783</td>\n",
       "      <td>-0.253843</td>\n",
       "      <td>-0.978381</td>\n",
       "      <td>0.062454</td>\n",
       "      <td>-0.439381</td>\n",
       "      <td>0.206277</td>\n",
       "      <td>-0.491717</td>\n",
       "      <td>-0.671706</td>\n",
       "      <td>0.510458</td>\n",
       "      <td>0.440922</td>\n",
       "      <td>-0.750095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>1.628638</td>\n",
       "      <td>-0.493756</td>\n",
       "      <td>1.030676</td>\n",
       "      <td>-0.253843</td>\n",
       "      <td>1.322705</td>\n",
       "      <td>-0.440908</td>\n",
       "      <td>0.987891</td>\n",
       "      <td>-0.977766</td>\n",
       "      <td>1.739447</td>\n",
       "      <td>1.626982</td>\n",
       "      <td>0.903252</td>\n",
       "      <td>-3.646450</td>\n",
       "      <td>1.685303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>-0.415081</td>\n",
       "      <td>0.035767</td>\n",
       "      <td>-0.704852</td>\n",
       "      <td>-0.253843</td>\n",
       "      <td>0.074234</td>\n",
       "      <td>-0.423895</td>\n",
       "      <td>-1.179062</td>\n",
       "      <td>1.246377</td>\n",
       "      <td>-0.609147</td>\n",
       "      <td>-0.340743</td>\n",
       "      <td>0.122496</td>\n",
       "      <td>0.427226</td>\n",
       "      <td>-0.465925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>379 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "440  2.461191 -0.493756  1.043701 -0.253843  2.176443 -0.380567  0.883710   \n",
       "215 -0.405195 -0.493756 -0.047764 -0.253843  0.142332 -0.368518 -0.852630   \n",
       "212 -0.397808 -0.493756 -0.047053  3.929048  0.359076 -0.569274 -0.456745   \n",
       "197 -0.442869  2.895194 -1.404919 -0.253843 -0.214641  1.418611 -1.054046   \n",
       "161 -0.239866 -0.493756  1.268183 -0.253843 -0.486640  1.577468  0.828147   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "250 -0.423351  0.438205 -0.737501 -0.253843 -0.990238  0.452606 -1.873599   \n",
       "234 -0.400441 -0.493756 -0.664914  3.929048 -0.192388  0.683444 -0.015714   \n",
       "321 -0.391643 -0.493756 -0.496783 -0.253843 -0.978381  0.062454 -0.439381   \n",
       "425  1.628638 -0.493756  1.030676 -0.253843  1.322705 -0.440908  0.987891   \n",
       "69  -0.415081  0.035767 -0.704852 -0.253843  0.074234 -0.423895 -1.179062   \n",
       "\n",
       "          DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "440 -0.874098  1.739447  1.620964  0.895841  0.372297  1.380542  \n",
       "215 -0.040545 -0.609147 -0.780021  0.080206  0.426898 -0.468251  \n",
       "212 -0.035133 -0.609147 -0.725864  0.156269  0.396322  0.494088  \n",
       "197  1.592479 -0.844007 -0.455076 -2.695897 -0.009380 -0.518972  \n",
       "161 -0.924382 -0.491717  0.038360 -1.766346  0.208786 -1.466380  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "250  1.514291 -0.256858 -0.449058  0.214392  0.434080 -0.961680  \n",
       "234 -0.110129 -0.139428 -0.539321 -0.442409  0.048583 -0.640217  \n",
       "321  0.206277 -0.491717 -0.671706  0.510458  0.440922 -0.750095  \n",
       "425 -0.977766  1.739447  1.626982  0.903252 -3.646450  1.685303  \n",
       "69   1.246377 -0.609147 -0.340743  0.122496  0.427226 -0.465925  \n",
       "\n",
       "[379 rows x 13 columns]"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funtion that takes in features for the NN method\n",
    "def NearestNeighborOnFeatures(features, train, y_train, test, y_test, L):\n",
    "    curr_x_train = train.copy()[features]\n",
    "    curr_y_train = y_train.copy()\n",
    "    curr_x_test = test.copy()[features]\n",
    "    curr_y_test = y_test.copy()\n",
    "\n",
    "    return nneighbor(curr_x_train, curr_y_train, curr_x_test, curr_y_test, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIM' 'CHAS']\n",
      "Time taken: 5.87 seconds\n",
      "The test rmse is: \n",
      "12.756671868687159\n"
     ]
    }
   ],
   "source": [
    "# Trying a NN on a random 2 feature\n",
    "import random\n",
    "\n",
    "col_num = len(x_train.columns)\n",
    "k = 2\n",
    "random_k_features_index = random.sample(range(col_num), k)\n",
    "random_k_features = x_train.columns.values[random_k_features_index]\n",
    "\n",
    "print(random_k_features)\n",
    "rmse_1 = NearestNeighborOnFeatures(random_k_features, train, y_train, test, y_test,2)\n",
    "\n",
    "print('The test rmse is: ')\n",
    "print(rmse_1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 5.16 seconds\n",
      "The same features test rmse for L is 1 is: \n",
      "11.85026661715414\n"
     ]
    }
   ],
   "source": [
    "rmse_2 = NearestNeighborOnFeatures(['CRIM','CHAS'], train, y_train, test, y_test,1)\n",
    "print('The same features test rmse for L is 1 is: ')\n",
    "print(rmse_2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIM' 'DIS' 'TAX' 'INDUS' 'RM' 'NOX' 'CHAS']\n",
      "Time taken: 5.71 seconds\n",
      "The test rmse is: \n",
      "10.823152494595087\n"
     ]
    }
   ],
   "source": [
    "# trying a NN on a feature more than 4\n",
    "col_num = len(x_train.columns)\n",
    "k = 7\n",
    "random_k_features_index = random.sample(range(col_num), k)\n",
    "random_k_features = x_train.columns.values[random_k_features_index]\n",
    "\n",
    "print(random_k_features)\n",
    "rmse_7 = NearestNeighborOnFeatures(random_k_features, train, y_train, test, y_test,2)\n",
    "\n",
    "print('The test rmse is: ')\n",
    "print(rmse_7[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try every combination of any 2 features\n",
    "import math\n",
    "def SearchBestTwoFeatures(norm_x_train, y_train, norm_x_test, y_test):\n",
    "\n",
    "    col_num = len(norm_x_train.columns)\n",
    "\n",
    "    min_test_rmse = float('inf')\n",
    "    min_test_rmse_features = None\n",
    "    min_L = -1\n",
    "\n",
    "    for i in range(col_num - 1):\n",
    "        for j in range(i + 1, col_num):\n",
    "            curr_features = [norm_x_train.columns[i], norm_x_train.columns[j]]\n",
    "            print(curr_features)\n",
    "            for L in range(1,3):\n",
    "                curr_train_rmse, curr_test_rmse = NearestNeighborOnFeatures(curr_features,train, y_train, test, y_test, L)\n",
    "                if math.isinf(min_test_rmse) or curr_test_rmse < min_test_rmse:\n",
    "                    min_test_rmse = curr_test_rmse\n",
    "                    min_test_rmse_features = curr_features\n",
    "                    min_L = L\n",
    "    return min_test_rmse, min_test_rmse_features, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIM', 'ZN']\n",
      "Time taken: 5.24 seconds\n",
      "Time taken: 5.85 seconds\n",
      "['CRIM', 'INDUS']\n",
      "Time taken: 5.43 seconds\n",
      "Time taken: 5.68 seconds\n",
      "['CRIM', 'CHAS']\n",
      "Time taken: 5.36 seconds\n",
      "Time taken: 6.13 seconds\n",
      "['CRIM', 'NOX']\n",
      "Time taken: 5.43 seconds\n",
      "Time taken: 5.89 seconds\n",
      "['CRIM', 'RM']\n",
      "Time taken: 5.31 seconds\n",
      "Time taken: 6.01 seconds\n",
      "['CRIM', 'AGE']\n",
      "Time taken: 5.17 seconds\n",
      "Time taken: 5.75 seconds\n",
      "['CRIM', 'DIS']\n",
      "Time taken: 4.85 seconds\n",
      "Time taken: 5.44 seconds\n",
      "['CRIM', 'RAD']\n",
      "Time taken: 5.02 seconds\n",
      "Time taken: 5.81 seconds\n",
      "['CRIM', 'TAX']\n",
      "Time taken: 4.83 seconds\n",
      "Time taken: 5.37 seconds\n",
      "['CRIM', 'PTRATIO']\n",
      "Time taken: 4.73 seconds\n",
      "Time taken: 5.70 seconds\n",
      "['CRIM', 'B']\n",
      "Time taken: 5.16 seconds\n",
      "Time taken: 5.85 seconds\n",
      "['CRIM', 'LSTAT']\n",
      "Time taken: 5.04 seconds\n",
      "Time taken: 5.47 seconds\n",
      "['ZN', 'INDUS']\n",
      "Time taken: 4.72 seconds\n",
      "Time taken: 5.32 seconds\n",
      "['ZN', 'CHAS']\n",
      "Time taken: 4.67 seconds\n",
      "Time taken: 5.35 seconds\n",
      "['ZN', 'NOX']\n",
      "Time taken: 4.99 seconds\n",
      "Time taken: 5.55 seconds\n",
      "['ZN', 'RM']\n",
      "Time taken: 4.77 seconds\n",
      "Time taken: 5.64 seconds\n",
      "['ZN', 'AGE']\n",
      "Time taken: 5.00 seconds\n",
      "Time taken: 5.39 seconds\n",
      "['ZN', 'DIS']\n",
      "Time taken: 4.96 seconds\n",
      "Time taken: 5.26 seconds\n",
      "['ZN', 'RAD']\n",
      "Time taken: 4.75 seconds\n",
      "Time taken: 5.43 seconds\n",
      "['ZN', 'TAX']\n",
      "Time taken: 5.67 seconds\n",
      "Time taken: 6.05 seconds\n",
      "['ZN', 'PTRATIO']\n",
      "Time taken: 5.65 seconds\n",
      "Time taken: 6.16 seconds\n",
      "['ZN', 'B']\n",
      "Time taken: 5.19 seconds\n",
      "Time taken: 5.99 seconds\n",
      "['ZN', 'LSTAT']\n",
      "Time taken: 5.21 seconds\n",
      "Time taken: 5.97 seconds\n",
      "['INDUS', 'CHAS']\n",
      "Time taken: 5.31 seconds\n",
      "Time taken: 5.73 seconds\n",
      "['INDUS', 'NOX']\n",
      "Time taken: 5.23 seconds\n",
      "Time taken: 5.78 seconds\n",
      "['INDUS', 'RM']\n",
      "Time taken: 5.23 seconds\n",
      "Time taken: 5.78 seconds\n",
      "['INDUS', 'AGE']\n",
      "Time taken: 4.91 seconds\n",
      "Time taken: 5.46 seconds\n",
      "['INDUS', 'DIS']\n",
      "Time taken: 5.04 seconds\n",
      "Time taken: 5.68 seconds\n",
      "['INDUS', 'RAD']\n",
      "Time taken: 4.98 seconds\n",
      "Time taken: 6.04 seconds\n",
      "['INDUS', 'TAX']\n",
      "Time taken: 5.10 seconds\n",
      "Time taken: 5.41 seconds\n",
      "['INDUS', 'PTRATIO']\n",
      "Time taken: 4.74 seconds\n",
      "Time taken: 5.61 seconds\n",
      "['INDUS', 'B']\n",
      "Time taken: 5.18 seconds\n",
      "Time taken: 6.02 seconds\n",
      "['INDUS', 'LSTAT']\n",
      "Time taken: 4.86 seconds\n",
      "Time taken: 5.60 seconds\n",
      "['CHAS', 'NOX']\n",
      "Time taken: 4.93 seconds\n",
      "Time taken: 5.97 seconds\n",
      "['CHAS', 'RM']\n",
      "Time taken: 5.32 seconds\n",
      "Time taken: 5.64 seconds\n",
      "['CHAS', 'AGE']\n",
      "Time taken: 5.11 seconds\n",
      "Time taken: 5.71 seconds\n",
      "['CHAS', 'DIS']\n",
      "Time taken: 5.36 seconds\n",
      "Time taken: 5.96 seconds\n",
      "['CHAS', 'RAD']\n",
      "Time taken: 5.08 seconds\n",
      "Time taken: 5.65 seconds\n",
      "['CHAS', 'TAX']\n",
      "Time taken: 4.95 seconds\n",
      "Time taken: 5.56 seconds\n",
      "['CHAS', 'PTRATIO']\n",
      "Time taken: 5.17 seconds\n",
      "Time taken: 5.87 seconds\n",
      "['CHAS', 'B']\n",
      "Time taken: 5.25 seconds\n",
      "Time taken: 5.47 seconds\n",
      "['CHAS', 'LSTAT']\n",
      "Time taken: 5.16 seconds\n",
      "Time taken: 6.05 seconds\n",
      "['NOX', 'RM']\n",
      "Time taken: 5.02 seconds\n",
      "Time taken: 5.48 seconds\n",
      "['NOX', 'AGE']\n",
      "Time taken: 4.99 seconds\n",
      "Time taken: 5.56 seconds\n",
      "['NOX', 'DIS']\n",
      "Time taken: 5.31 seconds\n",
      "Time taken: 5.69 seconds\n",
      "['NOX', 'RAD']\n",
      "Time taken: 4.95 seconds\n",
      "Time taken: 5.76 seconds\n",
      "['NOX', 'TAX']\n",
      "Time taken: 5.17 seconds\n",
      "Time taken: 5.89 seconds\n",
      "['NOX', 'PTRATIO']\n",
      "Time taken: 4.98 seconds\n",
      "Time taken: 5.63 seconds\n",
      "['NOX', 'B']\n",
      "Time taken: 5.00 seconds\n",
      "Time taken: 5.46 seconds\n",
      "['NOX', 'LSTAT']\n",
      "Time taken: 5.04 seconds\n",
      "Time taken: 5.86 seconds\n",
      "['RM', 'AGE']\n",
      "Time taken: 5.16 seconds\n",
      "Time taken: 5.38 seconds\n",
      "['RM', 'DIS']\n",
      "Time taken: 5.04 seconds\n",
      "Time taken: 5.56 seconds\n",
      "['RM', 'RAD']\n",
      "Time taken: 5.10 seconds\n",
      "Time taken: 5.53 seconds\n",
      "['RM', 'TAX']\n",
      "Time taken: 4.81 seconds\n",
      "Time taken: 5.46 seconds\n",
      "['RM', 'PTRATIO']\n",
      "Time taken: 4.79 seconds\n",
      "Time taken: 5.81 seconds\n",
      "['RM', 'B']\n",
      "Time taken: 5.25 seconds\n",
      "Time taken: 5.79 seconds\n",
      "['RM', 'LSTAT']\n",
      "Time taken: 5.25 seconds\n",
      "Time taken: 5.81 seconds\n",
      "['AGE', 'DIS']\n",
      "Time taken: 5.02 seconds\n",
      "Time taken: 5.31 seconds\n",
      "['AGE', 'RAD']\n",
      "Time taken: 4.64 seconds\n",
      "Time taken: 5.34 seconds\n",
      "['AGE', 'TAX']\n",
      "Time taken: 4.98 seconds\n",
      "Time taken: 5.28 seconds\n",
      "['AGE', 'PTRATIO']\n",
      "Time taken: 5.07 seconds\n",
      "Time taken: 5.60 seconds\n",
      "['AGE', 'B']\n",
      "Time taken: 4.81 seconds\n",
      "Time taken: 5.44 seconds\n",
      "['AGE', 'LSTAT']\n",
      "Time taken: 4.93 seconds\n",
      "Time taken: 5.57 seconds\n",
      "['DIS', 'RAD']\n",
      "Time taken: 5.34 seconds\n",
      "Time taken: 6.01 seconds\n",
      "['DIS', 'TAX']\n",
      "Time taken: 5.05 seconds\n",
      "Time taken: 5.95 seconds\n",
      "['DIS', 'PTRATIO']\n",
      "Time taken: 5.18 seconds\n",
      "Time taken: 5.53 seconds\n",
      "['DIS', 'B']\n",
      "Time taken: 4.85 seconds\n",
      "Time taken: 5.80 seconds\n",
      "['DIS', 'LSTAT']\n",
      "Time taken: 4.94 seconds\n",
      "Time taken: 5.61 seconds\n",
      "['RAD', 'TAX']\n",
      "Time taken: 5.12 seconds\n",
      "Time taken: 5.72 seconds\n",
      "['RAD', 'PTRATIO']\n",
      "Time taken: 5.03 seconds\n",
      "Time taken: 5.54 seconds\n",
      "['RAD', 'B']\n",
      "Time taken: 5.05 seconds\n",
      "Time taken: 5.66 seconds\n",
      "['RAD', 'LSTAT']\n",
      "Time taken: 5.45 seconds\n",
      "Time taken: 5.36 seconds\n",
      "['TAX', 'PTRATIO']\n",
      "Time taken: 5.05 seconds\n",
      "Time taken: 5.63 seconds\n",
      "['TAX', 'B']\n",
      "Time taken: 4.92 seconds\n",
      "Time taken: 5.71 seconds\n",
      "['TAX', 'LSTAT']\n",
      "Time taken: 5.32 seconds\n",
      "Time taken: 5.51 seconds\n",
      "['PTRATIO', 'B']\n",
      "Time taken: 5.06 seconds\n",
      "Time taken: 5.41 seconds\n",
      "['PTRATIO', 'LSTAT']\n",
      "Time taken: 4.93 seconds\n",
      "Time taken: 5.49 seconds\n",
      "['B', 'LSTAT']\n",
      "Time taken: 5.09 seconds\n",
      "Time taken: 5.57 seconds\n",
      "6.026559509792131 ['DIS', 'LSTAT'] 2\n"
     ]
    }
   ],
   "source": [
    "min_test_rmse, min_test_rmse_features, best_L = SearchBestTwoFeatures(x_train,y_train,x_test,y_test)\n",
    "print(min_test_rmse, min_test_rmse_features, best_L)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 5.71 seconds\n",
      "The test rmse is: \n",
      "7.746413953169444\n"
     ]
    }
   ],
   "source": [
    "rmse_3 = NearestNeighborOnFeatures(['DIS', 'LSTAT'], train, y_train, test, y_test,2)\n",
    "print('The test rmse is: ')\n",
    "print(rmse_3[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What combination of features and distance function provide the lowest RMSE on the test set? Do your decisions affect the running time of the algorithm?\n",
    "\n",
    "- The best feature combination are DIS and LSTAT with the value of L being 2. The test RMSE is 7.7464.\n",
    "- The run time is considered constant for each set of NN calculation regarless of the number of features selected. Changing L value doesn't affect run time significantly. The run time increased here because the extra function I implemented in each test cases for efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Cross-Validation\n",
    "\n",
    "The more you tinkered with your features and distance function, the higher the risk that you overfit your training data.  One solution to this sort of overfitting is to use cross-validation (see K-fold [cross-validation][1].  Here you must implement a simple k-fold cross-validation algorithm yourself.  The function you write here will be used several more times in this problem set, so do your best to write efficient code! (Note that the sklearn package has a built-in [K-fold][2] iterator -- you should *not* be invoking that or any related algorithms in this section of the problem set.)\n",
    "\n",
    "Use 50-fold cross-validation and report the average RMSE for Nearest Neighbors using Euclidean distance with `CRIM,RM and ZN` input features, as well as the total running time for the full run of 50 folds.  In other words, randomly divide your training dataset (created in 1.2) into 50 equally-sized samples.\n",
    "\n",
    "For each of the 50 iterations (the \"folds\"), use 49 samples as \"training data\" (even though there is no training in k-NN!), and the remaining 1 sample for validation.  Compute the RMSE of that particular validation set, then move on to the next iteration.  \n",
    "\n",
    " - Report the average cross-validated RMSE across the 50 iterations. What do you observe?\n",
    " \n",
    " - Create a histogram of the RMSEs for the folds (there should be 50 of these). Additionally, use a horizontal line to mark the average cross-validated RMSE.\n",
    "\n",
    "\n",
    "[1]: http://en.wikipedia.org/wiki/Cross-validation_(statistics)\n",
    "[2]: http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation\n",
    "\n",
    "\n",
    "\n",
    "NOTE: To perform any randomized operation, only use functions in the *numpy library (np.random)*. Do not use other packages for random functions.\n",
    "\n",
    "HINT: Running 50-fold cross validation might be time-consuming. Try starting with 5 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.51059631949621\n"
     ]
    }
   ],
   "source": [
    "#initializing values\n",
    "k = 50\n",
    "folds = np.array_split(optNN_train_df, k)\n",
    "total_rmse = 0\n",
    "rmse_list = []\n",
    "\n",
    "for i in range(k):\n",
    "    #split into test and validation set\n",
    "    train_df = folds.copy()\n",
    "    validation_df = folds[i]\n",
    "    \n",
    "    del train_df[i]\n",
    "    train_df = pd.concat(train_df, sort= False)\n",
    "    \n",
    "    #set the value\n",
    "    train_x_df = train_df[['CRIM_opt', 'RM_opt', 'ZN_opt']]\n",
    "    train_y_df = train_df['MEDV']\n",
    "\n",
    "    validation_x_df = validation_df[['CRIM_opt', 'RM_opt', 'ZN_opt']]\n",
    "    validation_y_df = validation_df['MEDV']\n",
    "    \n",
    "    rmse = nneighbortest(train_x_df,train_y_df, validation_x_df,validation_y_df, 2)\n",
    "    \n",
    "    #calculate rmse and average\n",
    "    rmse_list.append(rmse[0])\n",
    "    \n",
    "    total_rmse += rmse[0]\n",
    "\n",
    "average_rmse = total_rmse / k\n",
    "    \n",
    "print(average_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Data')"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the rmse graph\n",
    "test_rmse_min = min(rmse_list)\n",
    "test_rmse_max = max(rmse_list)\n",
    "\n",
    "num_bins = (math.ceil(test_rmse_max) - math.floor(test_rmse_min)) * 5\n",
    "plt.hist(rmse_list, bins=num_bins, range=[test_rmse_min, test_rmse_max])\n",
    "plt.axvline(x = average_rmse, c=\"r\")\n",
    "\n",
    "\n",
    "plt.ylabel('Probability')\n",
    "plt.xlabel('Data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the varaince is big, probably from 3 to 22; several range of most possible RMSE are around 8, 9 ish, the average RMSE acorss 50 folds is around 10.51. \n",
    "- there's a general trend of distribution acound probability at 0.01."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 K-Nearest Neighbors Algorithm\n",
    "\n",
    "Implement the K-Nearest Neighbors algorithm.  Use 10-fold cross validation and L2 normalization, and the same features as in 2.5. Report the RMSE for K=4 and the running time of the algorithm. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "K-Nearest Neighbors\n",
    "\n",
    "Implementation of nearest neighbors algorithm.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "x_train: array\n",
    "    Array of numerical feature values for training the model.\n",
    "y_train: array\n",
    "    Array of numerical output values for training the model.\n",
    "x_test: array\n",
    "    Array of numerical feature values for testing the model.\n",
    "y_test: array\n",
    "    Array of numerical output values for testing the model.\n",
    "L: int\n",
    "    Order of L-norm function used for calculating distance.\n",
    "K: int\n",
    "    Neighbors to include in algorithm\n",
    "    \n",
    "Returns\n",
    "-------\n",
    "rmse : int\n",
    "    Value of the RMSE from data.\n",
    "\"\"\"\n",
    "\n",
    "def knn(x_train, y_train, x_test, y_test, L, K):\n",
    "    start_time = time.time()\n",
    "    #initiate the output list\n",
    "    output = []\n",
    "    \n",
    "    #loop the test/validation set value (this case k/length is 4)\n",
    "    for test in range(len(x_test)):\n",
    "        #initiate the distance list\n",
    "        d = []\n",
    "        \n",
    "        #get the individual test/validation row values\n",
    "        test_row = x_test.iloc[test].values\n",
    "        \n",
    "        #loop the train value for comparison\n",
    "        for train in range(len(x_train)):\n",
    "            #get the individual train set row value\n",
    "            train_row = x_train.iloc[train].values\n",
    "            #append the distance between each validation row value and the test train set row value\n",
    "            d.append(distance(train_row, test_row, 2))\n",
    "            \n",
    "        #convert distance list to dataframe    \n",
    "        df_dists = pd.DataFrame(data= d, index= y_train.index, columns= ['dist'])\n",
    "        \n",
    "        #sort the distance ascending and get the first k values\n",
    "        df_nn = df_dists.sort_values(by=['dist'], axis=0)[:K]\n",
    "        #get the index of theses k value\n",
    "        df_idx = df_nn.index    \n",
    "        #calculate the mean y value based on the k y predict value\n",
    "        mean_k = y_train.loc[df_idx].mean()\n",
    "        \n",
    "        #append the row mean to the output list\n",
    "        output.append(mean_k)\n",
    "    \n",
    "    #calculate the rmse \n",
    "    rmse = compute_rmse(output, y_test)\n",
    "    print(\"Time taken: {:.2f} seconds\".format(time.time() - start_time))\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 1.24 seconds\n",
      "Time taken: 1.14 seconds\n",
      "Time taken: 1.12 seconds\n",
      "Time taken: 1.16 seconds\n",
      "Time taken: 1.19 seconds\n",
      "Time taken: 1.18 seconds\n",
      "Time taken: 1.12 seconds\n",
      "Time taken: 1.16 seconds\n",
      "Time taken: 1.12 seconds\n",
      "Time taken: 1.11 seconds\n",
      "[8.523781553611299, 9.321621724729415, 8.542366359874517, 8.209563982908817, 7.1239322838029935, 8.149595364511246, 7.784647720454596, 10.756812406930537, 10.497523204120705, 10.291639220155254]\n",
      "8.920148382109938\n"
     ]
    }
   ],
   "source": [
    "# enter your additional code here\n",
    "k_f = 10\n",
    "folds = np.array_split(optNN_train_df, k_f)\n",
    "total_rmse = 0\n",
    "rmse_list = []\n",
    "\n",
    "for i in range(k_f):\n",
    "    #split into test and validation set\n",
    "    train_df = folds.copy()\n",
    "    validation_df = folds[i]\n",
    "    \n",
    "    del train_df[i]\n",
    "    train_df = pd.concat(train_df, sort= False)\n",
    "    \n",
    "    #set the value\n",
    "    train_x_df = train_df[['CRIM_opt', 'RM_opt', 'ZN_opt']]\n",
    "    train_y_df = train_df['MEDV']\n",
    "\n",
    "    validation_x_df = validation_df[['CRIM_opt', 'RM_opt', 'ZN_opt']]\n",
    "    validation_y_df = validation_df['MEDV']\n",
    "    \n",
    "    #calculate rmse for the knn while K neighbors is 4\n",
    "    rmse = knn(train_x_df,train_y_df, validation_x_df,validation_y_df, 2,4)\n",
    "    \n",
    "    #calculate rmse and average\n",
    "    rmse_list.append(rmse)\n",
    "    total_rmse += rmse\n",
    "    \n",
    "    average_rmse = total_rmse / k_f\n",
    "\n",
    "print(rmse_list)    \n",
    "print(average_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The rmse for 10-fold cross validation, k=4 is 8.92. \n",
    "- For calculating each fold, it takes around 1 sec. The overall calculation time takes around 10 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Using cross validation to find K\n",
    "\n",
    "Compute the cross-validated RMSE for values of K between 1 and 25 using 10-fold cross-validation and L2 normalization.  Use the following features in your model: `CRIM, ZN, RM, AGE, DIS, TAX`.  Create a graph that shows how cross-validated RMSE changes as K increases from 1 to 25.  Label your axes, and summarize what you see.  What do you think is a reasonable choice of K for this model?\n",
    "\n",
    "Finally, report the test RMSE using the value of K that minimized the cross-validated RMSE. (Continue to use L2 normalization and the same set of features). How does the test RMSE compare to the cross-validated RMSE, and is this what you expected? How does the test RMSE compare to the test RMSE from 2.4, and is this what you expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGE SD: 28.75817952331717 AGE mean: 66.95250659630607\n",
      "DIS SD: 2.165302666121738 DIS mean: 4.1200410108596275\n",
      "TAX SD: 165.96237928305402 TAX mean: 409.6253298153034\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM_opt</th>\n",
       "      <th>ZN_opt</th>\n",
       "      <th>RM_opt</th>\n",
       "      <th>AGE_opt</th>\n",
       "      <th>DIS_opt</th>\n",
       "      <th>TAX_opt</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>2.464445</td>\n",
       "      <td>-0.494409</td>\n",
       "      <td>-0.381070</td>\n",
       "      <td>0.884878</td>\n",
       "      <td>-0.875253</td>\n",
       "      <td>1.623107</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>-0.405731</td>\n",
       "      <td>-0.494409</td>\n",
       "      <td>-0.369005</td>\n",
       "      <td>-0.853757</td>\n",
       "      <td>-0.040599</td>\n",
       "      <td>-0.781052</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>-0.398334</td>\n",
       "      <td>-0.494409</td>\n",
       "      <td>-0.570027</td>\n",
       "      <td>-0.457348</td>\n",
       "      <td>-0.035179</td>\n",
       "      <td>-0.726823</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>-0.443454</td>\n",
       "      <td>2.899021</td>\n",
       "      <td>1.420486</td>\n",
       "      <td>-1.055439</td>\n",
       "      <td>1.594584</td>\n",
       "      <td>-0.455678</td>\n",
       "      <td>30.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>-0.240184</td>\n",
       "      <td>-0.494409</td>\n",
       "      <td>1.579553</td>\n",
       "      <td>0.829242</td>\n",
       "      <td>-0.925604</td>\n",
       "      <td>0.038410</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>-0.423911</td>\n",
       "      <td>0.438784</td>\n",
       "      <td>0.453204</td>\n",
       "      <td>-1.876075</td>\n",
       "      <td>1.516293</td>\n",
       "      <td>-0.449652</td>\n",
       "      <td>24.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>-0.400970</td>\n",
       "      <td>-0.494409</td>\n",
       "      <td>0.684348</td>\n",
       "      <td>-0.015735</td>\n",
       "      <td>-0.110274</td>\n",
       "      <td>-0.540034</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>-0.392161</td>\n",
       "      <td>-0.494409</td>\n",
       "      <td>0.062537</td>\n",
       "      <td>-0.439962</td>\n",
       "      <td>0.206550</td>\n",
       "      <td>-0.672594</td>\n",
       "      <td>23.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>1.630790</td>\n",
       "      <td>-0.494409</td>\n",
       "      <td>-0.441491</td>\n",
       "      <td>0.989197</td>\n",
       "      <td>-0.979058</td>\n",
       "      <td>1.629132</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>-0.415630</td>\n",
       "      <td>0.035815</td>\n",
       "      <td>-0.424455</td>\n",
       "      <td>-1.180621</td>\n",
       "      <td>1.248025</td>\n",
       "      <td>-0.341194</td>\n",
       "      <td>20.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>379 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CRIM_opt    ZN_opt    RM_opt   AGE_opt   DIS_opt   TAX_opt  MEDV\n",
       "440  2.464445 -0.494409 -0.381070  0.884878 -0.875253  1.623107  10.5\n",
       "215 -0.405731 -0.494409 -0.369005 -0.853757 -0.040599 -0.781052  25.0\n",
       "212 -0.398334 -0.494409 -0.570027 -0.457348 -0.035179 -0.726823  22.4\n",
       "197 -0.443454  2.899021  1.420486 -1.055439  1.594584 -0.455678  30.3\n",
       "161 -0.240184 -0.494409  1.579553  0.829242 -0.925604  0.038410  50.0\n",
       "..        ...       ...       ...       ...       ...       ...   ...\n",
       "250 -0.423911  0.438784  0.453204 -1.876075  1.516293 -0.449652  24.4\n",
       "234 -0.400970 -0.494409  0.684348 -0.015735 -0.110274 -0.540034  29.0\n",
       "321 -0.392161 -0.494409  0.062537 -0.439962  0.206550 -0.672594  23.1\n",
       "425  1.630790 -0.494409 -0.441491  0.989197 -0.979058  1.629132   8.3\n",
       "69  -0.415630  0.035815 -0.424455 -1.180621  1.248025 -0.341194  20.9\n",
       "\n",
       "[379 rows x 7 columns]"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create needed df with the updated standardized value\n",
    "cv_train_df_b = bdata_train[['AGE', 'DIS', 'TAX']]\n",
    "\n",
    "raw_AGE = normalize(cv_train_df_b['AGE'])\n",
    "optNN_train_df['AGE_opt'] = raw_AGE[0] \n",
    "print('AGE SD: ' + str(raw_AGE[1]) + ' AGE mean: ' + str(raw_AGE[2]))\n",
    "\n",
    "raw_DIS = normalize(cv_train_df_b['DIS'])\n",
    "optNN_train_df['DIS_opt'] = raw_DIS[0]\n",
    "print('DIS SD: ' + str(raw_DIS[1]) + ' DIS mean: ' + str(raw_DIS[2]))\n",
    "\n",
    "raw_TAX = normalize(cv_train_df_b['TAX'])\n",
    "optNN_train_df['TAX_opt'] = raw_TAX[0]\n",
    "print('TAX SD: ' + str(raw_TAX[1]) + ' TAX mean: '+ str(raw_TAX[2]))\n",
    "\n",
    "cv_train_df = optNN_train_df[['CRIM_opt', 'ZN_opt', 'RM_opt','AGE_opt', 'DIS_opt', 'TAX_opt','MEDV']]\n",
    "cv_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 1.19 seconds\n",
      "Time taken: 1.16 seconds\n",
      "Time taken: 1.38 seconds\n",
      "Time taken: 1.29 seconds\n",
      "Time taken: 1.29 seconds\n",
      "Time taken: 1.17 seconds\n",
      "Time taken: 1.32 seconds\n",
      "Time taken: 1.18 seconds\n",
      "Time taken: 1.10 seconds\n",
      "Time taken: 1.08 seconds\n",
      "Time taken: 1.11 seconds\n",
      "Time taken: 1.15 seconds\n",
      "Time taken: 1.14 seconds\n",
      "Time taken: 1.12 seconds\n",
      "Time taken: 1.10 seconds\n",
      "Time taken: 1.08 seconds\n",
      "Time taken: 1.08 seconds\n",
      "Time taken: 1.21 seconds\n",
      "Time taken: 1.12 seconds\n",
      "Time taken: 1.10 seconds\n",
      "Time taken: 1.14 seconds\n",
      "Time taken: 1.20 seconds\n",
      "Time taken: 1.36 seconds\n",
      "Time taken: 1.27 seconds\n",
      "Time taken: 1.17 seconds\n",
      "Time taken: 1.19 seconds\n",
      "Time taken: 1.13 seconds\n",
      "Time taken: 1.17 seconds\n",
      "Time taken: 1.10 seconds\n",
      "Time taken: 1.10 seconds\n",
      "Time taken: 1.13 seconds\n",
      "Time taken: 1.09 seconds\n",
      "Time taken: 1.23 seconds\n",
      "Time taken: 1.21 seconds\n",
      "Time taken: 1.14 seconds\n",
      "Time taken: 1.12 seconds\n",
      "Time taken: 1.09 seconds\n",
      "Time taken: 1.10 seconds\n",
      "Time taken: 1.19 seconds\n",
      "Time taken: 1.10 seconds\n",
      "Time taken: 1.13 seconds\n",
      "Time taken: 1.10 seconds\n",
      "Time taken: 1.10 seconds\n",
      "Time taken: 1.17 seconds\n",
      "Time taken: 1.14 seconds\n",
      "Time taken: 1.13 seconds\n",
      "Time taken: 1.12 seconds\n",
      "Time taken: 1.15 seconds\n",
      "Time taken: 1.19 seconds\n",
      "Time taken: 1.11 seconds\n",
      "Time taken: 1.19 seconds\n",
      "Time taken: 1.21 seconds\n",
      "Time taken: 1.15 seconds\n",
      "Time taken: 1.18 seconds\n",
      "Time taken: 1.20 seconds\n",
      "Time taken: 1.12 seconds\n",
      "Time taken: 1.12 seconds\n",
      "Time taken: 1.13 seconds\n",
      "Time taken: 1.16 seconds\n",
      "Time taken: 1.16 seconds\n",
      "Time taken: 1.16 seconds\n",
      "Time taken: 1.10 seconds\n",
      "Time taken: 1.10 seconds\n",
      "Time taken: 1.12 seconds\n",
      "Time taken: 1.17 seconds\n",
      "Time taken: 1.15 seconds\n",
      "Time taken: 1.26 seconds\n",
      "Time taken: 1.31 seconds\n",
      "Time taken: 1.29 seconds\n",
      "Time taken: 1.12 seconds\n",
      "Time taken: 1.18 seconds\n",
      "Time taken: 1.14 seconds\n",
      "Time taken: 1.15 seconds\n",
      "Time taken: 1.15 seconds\n",
      "Time taken: 1.13 seconds\n",
      "Time taken: 1.20 seconds\n",
      "Time taken: 1.13 seconds\n",
      "Time taken: 1.17 seconds\n",
      "Time taken: 1.18 seconds\n",
      "Time taken: 1.15 seconds\n",
      "Time taken: 1.21 seconds\n",
      "Time taken: 1.17 seconds\n",
      "Time taken: 1.15 seconds\n",
      "Time taken: 1.13 seconds\n",
      "Time taken: 1.17 seconds\n",
      "Time taken: 1.24 seconds\n",
      "Time taken: 1.13 seconds\n",
      "Time taken: 1.09 seconds\n",
      "Time taken: 1.11 seconds\n",
      "Time taken: 1.11 seconds\n",
      "Time taken: 1.21 seconds\n",
      "Time taken: 1.19 seconds\n",
      "Time taken: 1.24 seconds\n",
      "Time taken: 1.26 seconds\n",
      "Time taken: 1.25 seconds\n",
      "Time taken: 1.32 seconds\n",
      "Time taken: 1.14 seconds\n",
      "Time taken: 1.17 seconds\n",
      "Time taken: 1.25 seconds\n",
      "Time taken: 1.19 seconds\n",
      "Time taken: 1.31 seconds\n",
      "Time taken: 1.25 seconds\n",
      "Time taken: 1.19 seconds\n",
      "Time taken: 1.21 seconds\n",
      "Time taken: 1.23 seconds\n",
      "Time taken: 1.17 seconds\n",
      "Time taken: 1.32 seconds\n",
      "Time taken: 1.20 seconds\n",
      "Time taken: 1.16 seconds\n",
      "Time taken: 1.09 seconds\n",
      "Time taken: 1.16 seconds\n",
      "Time taken: 1.17 seconds\n",
      "Time taken: 1.32 seconds\n",
      "Time taken: 1.35 seconds\n",
      "Time taken: 1.23 seconds\n",
      "Time taken: 1.33 seconds\n",
      "Time taken: 1.24 seconds\n",
      "Time taken: 1.22 seconds\n",
      "Time taken: 1.38 seconds\n",
      "Time taken: 1.13 seconds\n",
      "Time taken: 1.19 seconds\n",
      "Time taken: 1.12 seconds\n",
      "Time taken: 1.10 seconds\n",
      "Time taken: 1.13 seconds\n",
      "Time taken: 1.34 seconds\n",
      "Time taken: 1.37 seconds\n",
      "Time taken: 1.11 seconds\n",
      "Time taken: 1.21 seconds\n",
      "Time taken: 1.20 seconds\n",
      "Time taken: 1.14 seconds\n",
      "Time taken: 1.27 seconds\n",
      "Time taken: 1.22 seconds\n",
      "Time taken: 1.29 seconds\n",
      "Time taken: 1.31 seconds\n",
      "Time taken: 1.17 seconds\n",
      "Time taken: 1.31 seconds\n",
      "Time taken: 1.30 seconds\n",
      "Time taken: 1.16 seconds\n",
      "Time taken: 1.14 seconds\n",
      "Time taken: 1.12 seconds\n",
      "Time taken: 1.12 seconds\n",
      "Time taken: 1.16 seconds\n",
      "Time taken: 1.13 seconds\n",
      "Time taken: 1.13 seconds\n",
      "Time taken: 1.14 seconds\n",
      "Time taken: 1.12 seconds\n",
      "Time taken: 1.19 seconds\n",
      "Time taken: 1.15 seconds\n",
      "Time taken: 1.20 seconds\n",
      "Time taken: 1.12 seconds\n",
      "Time taken: 1.14 seconds\n",
      "Time taken: 1.23 seconds\n",
      "Time taken: 1.15 seconds\n",
      "Time taken: 1.13 seconds\n",
      "Time taken: 1.12 seconds\n",
      "Time taken: 1.11 seconds\n",
      "Time taken: 1.20 seconds\n",
      "Time taken: 1.21 seconds\n",
      "Time taken: 1.15 seconds\n",
      "Time taken: 1.13 seconds\n",
      "Time taken: 1.22 seconds\n",
      "Time taken: 1.27 seconds\n",
      "Time taken: 1.36 seconds\n",
      "Time taken: 1.23 seconds\n",
      "Time taken: 1.35 seconds\n",
      "Time taken: 1.21 seconds\n",
      "Time taken: 1.18 seconds\n",
      "Time taken: 1.16 seconds\n",
      "Time taken: 1.14 seconds\n",
      "Time taken: 1.08 seconds\n",
      "Time taken: 1.12 seconds\n",
      "Time taken: 1.10 seconds\n",
      "Time taken: 1.19 seconds\n",
      "Time taken: 1.10 seconds\n",
      "Time taken: 1.18 seconds\n",
      "Time taken: 1.09 seconds\n",
      "Time taken: 1.15 seconds\n",
      "Time taken: 1.18 seconds\n",
      "Time taken: 1.09 seconds\n",
      "Time taken: 1.08 seconds\n",
      "Time taken: 1.09 seconds\n",
      "Time taken: 1.11 seconds\n",
      "Time taken: 1.18 seconds\n",
      "Time taken: 1.14 seconds\n",
      "Time taken: 1.11 seconds\n",
      "Time taken: 1.11 seconds\n",
      "Time taken: 1.09 seconds\n",
      "Time taken: 1.14 seconds\n",
      "Time taken: 1.16 seconds\n",
      "Time taken: 1.07 seconds\n",
      "Time taken: 1.10 seconds\n",
      "Time taken: 1.23 seconds\n",
      "Time taken: 1.07 seconds\n",
      "Time taken: 1.15 seconds\n",
      "Time taken: 1.14 seconds\n",
      "Time taken: 1.10 seconds\n",
      "Time taken: 1.10 seconds\n",
      "Time taken: 1.08 seconds\n",
      "Time taken: 1.13 seconds\n",
      "Time taken: 1.18 seconds\n",
      "Time taken: 1.12 seconds\n",
      "Time taken: 1.12 seconds\n",
      "Time taken: 1.10 seconds\n",
      "Time taken: 1.14 seconds\n",
      "Time taken: 1.21 seconds\n",
      "Time taken: 1.22 seconds\n",
      "Time taken: 1.24 seconds\n",
      "Time taken: 1.35 seconds\n",
      "Time taken: 1.58 seconds\n",
      "Time taken: 1.26 seconds\n",
      "Time taken: 1.20 seconds\n",
      "Time taken: 1.18 seconds\n",
      "Time taken: 1.16 seconds\n",
      "Time taken: 1.23 seconds\n",
      "Time taken: 1.23 seconds\n",
      "Time taken: 1.18 seconds\n",
      "Time taken: 1.21 seconds\n",
      "Time taken: 1.20 seconds\n",
      "Time taken: 1.12 seconds\n",
      "Time taken: 1.13 seconds\n",
      "Time taken: 1.14 seconds\n",
      "Time taken: 1.15 seconds\n",
      "Time taken: 1.11 seconds\n",
      "Time taken: 1.14 seconds\n",
      "Time taken: 1.16 seconds\n",
      "Time taken: 1.13 seconds\n",
      "Time taken: 1.15 seconds\n",
      "Time taken: 1.16 seconds\n",
      "Time taken: 1.23 seconds\n",
      "Time taken: 1.17 seconds\n",
      "Time taken: 1.20 seconds\n",
      "Time taken: 1.22 seconds\n",
      "Time taken: 1.16 seconds\n",
      "Time taken: 1.20 seconds\n",
      "Time taken: 1.22 seconds\n",
      "Time taken: 1.21 seconds\n",
      "Time taken: 1.16 seconds\n",
      "Time taken: 1.21 seconds\n",
      "Time taken: 1.19 seconds\n",
      "Time taken: 1.16 seconds\n",
      "Time taken: 1.18 seconds\n",
      "Time taken: 1.19 seconds\n",
      "Time taken: 1.21 seconds\n",
      "Time taken: 1.31 seconds\n",
      "Time taken: 1.22 seconds\n",
      "Time taken: 1.14 seconds\n",
      "Time taken: 1.10 seconds\n",
      "Time taken: 1.14 seconds\n",
      "Time taken: 1.15 seconds\n",
      "Time taken: 1.11 seconds\n",
      "[12.264420030913026, 10.741621620907564, 9.86849940470085, 9.705532908210737, 9.435586986717375, 9.231929868990951, 9.199572743276923, 9.358263871183059, 9.261908804429213, 9.192242099309583, 9.149633516513607, 9.184835224898508, 9.234038028128259, 9.145404735490608, 9.161154504794876, 9.133003866195757, 9.152054721138557, 9.101551575367216, 9.118813810876373, 9.08977783583051, 9.087082639232111, 9.014480506015571, 9.022469861629318, 9.03464917869824, 9.040117861848698]\n"
     ]
    }
   ],
   "source": [
    "#initialize value \n",
    "K = list(range(1, 26))\n",
    "k_f = 10\n",
    "folds = np.array_split(cv_train_df, k_f)\n",
    "K_rmse = []\n",
    "\n",
    "#loop through the K neighbors from 1-25\n",
    "for j in K:\n",
    "    #create list for the total rmse for each K neighbors iteration\n",
    "    total_rmse = 0\n",
    "    \n",
    "    #loop through each 10 folds\n",
    "    for i in range(k_f):\n",
    "        \n",
    "        #split into test and validation set\n",
    "        train_df = folds.copy()\n",
    "        validation_df = folds[i]\n",
    "\n",
    "        del train_df[i]\n",
    "        train_df = pd.concat(train_df, sort= False)\n",
    "\n",
    "        #set the value\n",
    "        train_x_df = train_df[['CRIM_opt', 'ZN_opt', 'RM_opt','AGE_opt', 'DIS_opt', 'TAX_opt']]\n",
    "        train_y_df = train_df['MEDV']\n",
    "\n",
    "        validation_x_df = validation_df[['CRIM_opt', 'ZN_opt', 'RM_opt','AGE_opt', 'DIS_opt', 'TAX_opt']]\n",
    "        validation_y_df = validation_df['MEDV']\n",
    "        \n",
    "        #calculate rmse for each iteration\n",
    "        rmse = knn(train_x_df,train_y_df, validation_x_df,validation_y_df, 2, j)\n",
    "    \n",
    "        #calculate rmse and average\n",
    "        total_rmse += rmse\n",
    "        \n",
    "    #calculate the average rmse for the iteration\n",
    "    average_rmse = total_rmse / k_f\n",
    "    \n",
    "    #append the average rmse for each K neighbor \n",
    "    K_rmse.append(average_rmse)\n",
    "\n",
    "print(K_rmse)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.264420</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.741622</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.868499</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.705533</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.435587</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.231930</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.199573</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.358264</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.261909</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.192242</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9.149634</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9.184835</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9.234038</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9.145405</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9.161155</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9.133004</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9.152055</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.101552</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9.118814</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9.089778</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9.087083</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9.014481</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9.022470</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9.034649</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9.040118</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RMSE   K\n",
       "0   12.264420   1\n",
       "1   10.741622   2\n",
       "2    9.868499   3\n",
       "3    9.705533   4\n",
       "4    9.435587   5\n",
       "5    9.231930   6\n",
       "6    9.199573   7\n",
       "7    9.358264   8\n",
       "8    9.261909   9\n",
       "9    9.192242  10\n",
       "10   9.149634  11\n",
       "11   9.184835  12\n",
       "12   9.234038  13\n",
       "13   9.145405  14\n",
       "14   9.161155  15\n",
       "15   9.133004  16\n",
       "16   9.152055  17\n",
       "17   9.101552  18\n",
       "18   9.118814  19\n",
       "19   9.089778  20\n",
       "20   9.087083  21\n",
       "21   9.014481  22\n",
       "22   9.022470  23\n",
       "23   9.034649  24\n",
       "24   9.040118  25"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataframe based on the rmse list \n",
    "k_df = pd.DataFrame(K_rmse, columns = ['RMSE'])\n",
    "k_df['K'] = K\n",
    "k_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.42499999999999716, 0.5, 'RMSE Value')"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create a scatter plot that shows the true value of each instance on the x-axis and the predicted value of each instance on the y-axis. Color the training instances in blue and the test instances in red. Make sure to label your axes appropriately, and add a legend to your figure to make clear which dots are which.\n",
    "#plt.scatter(k_df['K'], k_df['RMSE'], c='b')\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.lmplot(x='K',y='RMSE',data=k_df, fit_reg=True, ci = False)\n",
    "plt.title('cross-validated RMSE changes as K increase')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('RMSE Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9.014481</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RMSE   K\n",
       "21  9.014481  22"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the minimum RMSE and it's K value\n",
    "min_value = k_df['RMSE'].min() \n",
    "min_k = k_df.loc[k_df.RMSE == min_value]\n",
    "min_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the test rmse for k take the value of 22 is: \n",
      "Time taken: 4.26 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.630490902025244"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_test = bdata_test[['CRIM', 'ZN', 'RM','AGE', 'DIS', 'TAX']]\n",
    "cv_train = bdata_train[['CRIM', 'ZN', 'RM','AGE', 'DIS', 'TAX']]\n",
    "train_cv, test_cv = normalize_df(cv_train, cv_test)\n",
    "test_cv\n",
    "\n",
    "curr_y_train = optNN_train_df['MEDV']\n",
    "curr_y_test = optNN_test_df['MEDV']\n",
    "\n",
    "print('the test rmse for k take the value of 22 is: ')\n",
    "knn(train_cv, curr_y_train, test_cv, curr_y_test, 2, 22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the test RMSE compare to the cross-validated RMSE, and is this what you expected? How does the test RMSE compare to the test RMSE from 2.4, and is this what you expected?\n",
    "- The best cross RMSE is 9.01, the test RMSE is 9.63. Which is what I expected, the RMSE for test set is similar to the RMSE for the cross validate set. \n",
    "- The best RMSE from any 2 feature is 7.746; in this case the 6 features might be overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra-Credit: Forward selection\n",
    "\n",
    "Thus far the choice of predictor variables has been rather arbitrary. For extra credit, implement a basic [forward selection](https://see.stanford.edu/materials/aimlcs229/cs229-notes5.pdf) algorithm to progressively include features that decrease the cross-validated RMSE of the model. Note that the optimal value of K may be different for each model, so you may want to use cross-validation to choose K each time (but it is also fine if you fix K at the optimal value from 2.7).  Create a graph that shows RMSE as a function of the number of features in the model. Label each point on the x-axis with the name of the feature that is added at that step in the forward selection algorithm. *(For instance, if the optimal single-feature model has CRIM with RMSE = 10, and the optimal two-feature model has CRIM+ZN with RMSE=9, the first x-axis label will say CRIM and the second x-axis lable with say ZN)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
