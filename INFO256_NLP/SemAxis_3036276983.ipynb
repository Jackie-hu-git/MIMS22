{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[SemAxis](https://arxiv.org/pdf/1806.05521.pdf) is a method for scoring terms along a user-defined axis (e.g., positive-negative, concrete-abstract, hot-cold), which can be used for a range of empirical questions (for one example, see [Kozlowski et al. 2019](https://journals.sagepub.com/doi/full/10.1177/0003122419877135)). In this homework, you'll implement SemAxis using word representations from Glove, and use it to explore corpus-specific conceptual associations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running, install gensim with:\n",
    "\n",
    "`conda install gensim`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: ...working... failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\12062\\Anaconda3\\envs\\anlp\n",
      "\n",
      "  added / updated specs:\n",
      "    - gensim\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    boto3-1.18.21              |     pyhd3eb1b0_0          70 KB\n",
      "    botocore-1.21.21           |     pyhd3eb1b0_1         3.8 MB\n",
      "    bz2file-0.98               |   py38haa95532_1         246 KB\n",
      "    cython-0.29.23             |   py38hd77b12b_0         1.7 MB\n",
      "    gensim-4.0.1               |   py38hd77b12b_0        18.2 MB\n",
      "    jmespath-0.10.0            |     pyhd3eb1b0_0          22 KB\n",
      "    openssl-1.1.1l             |       h2bbff1b_0         4.8 MB\n",
      "    s3transfer-0.5.0           |     pyhd3eb1b0_0          57 KB\n",
      "    smart_open-1.9.0           |             py_0          56 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        29.0 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  boto               pkgs/main/win-64::boto-2.49.0-py38_0\n",
      "  boto3              pkgs/main/noarch::boto3-1.18.21-pyhd3eb1b0_0\n",
      "  botocore           pkgs/main/noarch::botocore-1.21.21-pyhd3eb1b0_1\n",
      "  bz2file            pkgs/main/win-64::bz2file-0.98-py38haa95532_1\n",
      "  cython             pkgs/main/win-64::cython-0.29.23-py38hd77b12b_0\n",
      "  gensim             pkgs/main/win-64::gensim-4.0.1-py38hd77b12b_0\n",
      "  jmespath           pkgs/main/noarch::jmespath-0.10.0-pyhd3eb1b0_0\n",
      "  s3transfer         pkgs/main/noarch::s3transfer-0.5.0-pyhd3eb1b0_0\n",
      "  smart_open         pkgs/main/noarch::smart_open-1.9.0-py_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  openssl                                 1.1.1k-h2bbff1b_0 --> 1.1.1l-h2bbff1b_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "cython-0.29.23       | 1.7 MB    |            |   0% \n",
      "cython-0.29.23       | 1.7 MB    | 3          |   4% \n",
      "cython-0.29.23       | 1.7 MB    | ##8        |  29% \n",
      "cython-0.29.23       | 1.7 MB    | #####      |  50% \n",
      "cython-0.29.23       | 1.7 MB    | ########3  |  83% \n",
      "\n",
      "cython-0.29.23       | 1.7 MB    | ########## | 100% \n",
      "\n",
      "boto3-1.18.21        | 70 KB     |            |   0% \n",
      "boto3-1.18.21        | 70 KB     | ########## | 100% \n",
      "boto3-1.18.21        | 70 KB     | ########## | 100% \n",
      "\n",
      "botocore-1.21.21     | 3.8 MB    |            |   0% \n",
      "botocore-1.21.21     | 3.8 MB    | 8          |   9% \n",
      "botocore-1.21.21     | 3.8 MB    | ##4        |  24% \n",
      "botocore-1.21.21     | 3.8 MB    | ####       |  41% \n",
      "botocore-1.21.21     | 3.8 MB    | #####5     |  56% \n",
      "botocore-1.21.21     | 3.8 MB    | #######3   |  74% \n",
      "botocore-1.21.21     | 3.8 MB    | #########2 |  92% \n",
      "botocore-1.21.21     | 3.8 MB    | ########## | 100% \n",
      "\n",
      "smart_open-1.9.0     | 56 KB     |            |   0% \n",
      "smart_open-1.9.0     | 56 KB     | ##8        |  28% \n",
      "smart_open-1.9.0     | 56 KB     | ########## | 100% \n",
      "smart_open-1.9.0     | 56 KB     | ########## | 100% \n",
      "\n",
      "jmespath-0.10.0      | 22 KB     |            |   0% \n",
      "jmespath-0.10.0      | 22 KB     | ########## | 100% \n",
      "jmespath-0.10.0      | 22 KB     | ########## | 100% \n",
      "\n",
      "s3transfer-0.5.0     | 57 KB     |            |   0% \n",
      "s3transfer-0.5.0     | 57 KB     | ########## | 100% \n",
      "s3transfer-0.5.0     | 57 KB     | ########## | 100% \n",
      "\n",
      "gensim-4.0.1         | 18.2 MB   |            |   0% \n",
      "gensim-4.0.1         | 18.2 MB   | 1          |   1% \n",
      "gensim-4.0.1         | 18.2 MB   | 4          |   5% \n",
      "gensim-4.0.1         | 18.2 MB   | 8          |   9% \n",
      "gensim-4.0.1         | 18.2 MB   | #2         |  12% \n",
      "gensim-4.0.1         | 18.2 MB   | #5         |  16% \n",
      "gensim-4.0.1         | 18.2 MB   | #9         |  19% \n",
      "gensim-4.0.1         | 18.2 MB   | ##2        |  22% \n",
      "gensim-4.0.1         | 18.2 MB   | ##5        |  25% \n",
      "gensim-4.0.1         | 18.2 MB   | ##9        |  29% \n",
      "gensim-4.0.1         | 18.2 MB   | ###2       |  33% \n",
      "gensim-4.0.1         | 18.2 MB   | ###5       |  36% \n",
      "gensim-4.0.1         | 18.2 MB   | ###9       |  40% \n",
      "gensim-4.0.1         | 18.2 MB   | ####3      |  43% \n",
      "gensim-4.0.1         | 18.2 MB   | ####6      |  47% \n",
      "gensim-4.0.1         | 18.2 MB   | #####      |  50% \n",
      "gensim-4.0.1         | 18.2 MB   | #####3     |  54% \n",
      "gensim-4.0.1         | 18.2 MB   | #####7     |  57% \n",
      "gensim-4.0.1         | 18.2 MB   | ######     |  61% \n",
      "gensim-4.0.1         | 18.2 MB   | ######3    |  64% \n",
      "gensim-4.0.1         | 18.2 MB   | ######7    |  67% \n",
      "gensim-4.0.1         | 18.2 MB   | #######    |  71% \n",
      "gensim-4.0.1         | 18.2 MB   | #######4   |  74% \n",
      "gensim-4.0.1         | 18.2 MB   | #######8   |  78% \n",
      "gensim-4.0.1         | 18.2 MB   | ########1  |  81% \n",
      "gensim-4.0.1         | 18.2 MB   | ########5  |  85% \n",
      "gensim-4.0.1         | 18.2 MB   | ########8  |  89% \n",
      "gensim-4.0.1         | 18.2 MB   | #########2 |  93% \n",
      "gensim-4.0.1         | 18.2 MB   | #########5 |  96% \n",
      "gensim-4.0.1         | 18.2 MB   | #########9 |  99% \n",
      "gensim-4.0.1         | 18.2 MB   | ########## | 100% \n",
      "\n",
      "bz2file-0.98         | 246 KB    |            |   0% \n",
      "bz2file-0.98         | 246 KB    | ########## | 100% \n",
      "bz2file-0.98         | 246 KB    | ########## | 100% \n",
      "\n",
      "openssl-1.1.1l       | 4.8 MB    |            |   0% \n",
      "openssl-1.1.1l       | 4.8 MB    | 7          |   8% \n",
      "openssl-1.1.1l       | 4.8 MB    | #8         |  18% \n",
      "openssl-1.1.1l       | 4.8 MB    | ##9        |  30% \n",
      "openssl-1.1.1l       | 4.8 MB    | ####       |  41% \n",
      "openssl-1.1.1l       | 4.8 MB    | #####1     |  51% \n",
      "openssl-1.1.1l       | 4.8 MB    | ######4    |  64% \n",
      "openssl-1.1.1l       | 4.8 MB    | #######5   |  75% \n",
      "openssl-1.1.1l       | 4.8 MB    | ########6  |  86% \n",
      "openssl-1.1.1l       | 4.8 MB    | #########7 |  97% \n",
      "openssl-1.1.1l       | 4.8 MB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    }
   ],
   "source": [
    "conda install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12062\\Anaconda3\\envs\\anlp\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "import numpy as np\n",
    "import numpy.linalg as LA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework, we'll be working with pre-trained word embeddings using the `gensim` library, which provides a number of functions for accessing representations for individual words and comparing them.  The representations we'll use come from [Glove](https://nlp.stanford.edu/projects/glove/), which are trained on web data from the [Common Crawl](https://en.wikipedia.org/wiki/Common_Crawl) corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-86a990e6d4aa>:4: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  _ = glove2word2vec(glove_file, glove_in_w2v_format)\n"
     ]
    }
   ],
   "source": [
    "# First we have to convert the Glove format into w2v format; this creates a new file\n",
    "glove_file=\"../data/glove.6B.100d.100K.txt\"\n",
    "glove_in_w2v_format=\"../data/glove.6B.100d.100K.w2v.txt\"\n",
    "_ = glove2word2vec(glove_file, glove_in_w2v_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = KeyedVectors.load_word2vec_format(\"../data/glove.6B.100d.100K.w2v.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_vector=glove[\"good\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions useful for the first question include the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,) (100,) (100,) [0.7592798]\n"
     ]
    }
   ],
   "source": [
    "# access the representation for a single word\n",
    "great_vector=glove[\"great\"]\n",
    "\n",
    "# use numpy to average multiple vector representations together\n",
    "vecs_to_average=[good_vector, great_vector]\n",
    "average=np.mean(vecs_to_average, axis=0)\n",
    "# calculate the cosine similariy between two vectors\n",
    "cosine_similarity=glove.cosine_similarities(good_vector, [great_vector])\n",
    "\n",
    "print(good_vector.shape, great_vector.shape, average.shape, cosine_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.** Read the SemAxis [paper](https://arxiv.org/pdf/1806.05521.pdf) and implement the SemAxis method described in sections 3.1.2 and 3.1.3.  Given a set of word embeddings for positive terms $S^+ = \\{v_1^+, \\ldots v_n^+\\}$ and embeddings for negative terms $S^- = \\{v_1^-, \\ldots v_n^-\\}$ that define the endpoints of the axis, your output should be a single real-value score for an input word $w$ with word representation $v_w$:\n",
    "\n",
    "$$\n",
    "score(w)_{\\mathbf{V_\\textrm{axis}}} = \\textrm{cos}(v_w, \\mathbf{V}_\\textrm{axis})\n",
    "$$\n",
    "\n",
    "Where: \n",
    "$$\n",
    "\\mathbf{V}^+ = {1 \\over n} \\sum_1^n v_i^+\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{V}^- = {1 \\over m} \\sum_1^m v_i^-\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{V}_{\\textrm{axis}} = \\mathbf{V}^+ - \\mathbf{V}^-\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_semaxis_score(vectors, positive_terms=None, negative_terms=None, target_word=None):\n",
    "    V_plus = []\n",
    "    V_neg = []\n",
    "    \n",
    "    # your code here\n",
    "    for p_word in positive_terms:\n",
    "        V_plus.append(vectors[p_word])\n",
    "        \n",
    "    for n_word in negative_terms:\n",
    "        V_neg.append(vectors[n_word])\n",
    "\n",
    "    average_p = np.mean(V_plus, axis=0)\n",
    "    average_n = np.mean(V_neg, axis=0)\n",
    "\n",
    "    V_axis = np.subtract(average_p , average_n)\n",
    "\n",
    "    # calculate the cosine similariy between two vectors\n",
    "    score = vectors.cosine_similarities(vectors[target_word], [V_axis])\n",
    "    \n",
    "    return score[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3424988"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should be 0.342\n",
    "get_semaxis_score(glove, positive_terms=[\"woman\", \"women\"], negative_terms=[\"man\", \"men\"], target_word=\"actress\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's score a set of target terms along that axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_list_of_targets(vectors, positive_terms=None, negative_terms=None, target_words=None):\n",
    "    scores=[]\n",
    "    for target in target_words:\n",
    "        scores.append((get_semaxis_score(vectors, positive_terms, negative_terms, target), target))\n",
    "\n",
    "    for k,v in reversed(sorted(scores)):\n",
    "        print(\"%.3f\\t%s\" % (k,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets=[\"doctor\", \"nurse\", \"actor\", \"actress\", \"mechanic\", \"librarian\", \"architect\", \"magician\", \"cook\", \"chef\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.342\tactress\n",
      "0.294\tnurse\n",
      "0.219\tlibrarian\n",
      "0.106\tdoctor\n",
      "0.024\tactor\n",
      "0.003\tchef\n",
      "-0.019\tcook\n",
      "-0.075\tarchitect\n",
      "-0.153\tmagician\n",
      "-0.194\tmechanic\n"
     ]
    }
   ],
   "source": [
    "score_list_of_targets(glove, positive_terms=[\"woman\", \"women\"], negative_terms=[\"man\", \"men\"], target_words=targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2:** Define your own concept axis by selecting a set of positive and negative terms and illustrate its utility by scoring a set of 10 target terms (as we did above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.493\tsharing\n",
      "0.330\tcontrol\n",
      "0.303\tmentor\n",
      "0.280\tcompetitive\n",
      "0.264\thumble\n",
      "0.199\tadmire\n",
      "0.127\tfrustration\n",
      "0.048\tplayful\n",
      "0.001\tanger\n",
      "-0.087\tjealous\n"
     ]
    }
   ],
   "source": [
    "positive_terms=['patience', 'love', 'knowledge', 'perseverance', 'faith', 'hope']\n",
    "negative_terms=['pride', 'greed', 'wrath', 'envy', 'lust', 'gluttony', 'sloth']\n",
    "targets=['jealous', 'control', 'playful', 'competitive', 'humble', 'admire', 'frustration', 'anger', 'mentor', 'sharing']\n",
    "\n",
    "score_list_of_targets(glove, positive_terms=positive_terms, negative_terms=negative_terms, target_words=targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3:** Let's assume now that you're able to score all words in a vocabulary along several conceptual dimensions (like the one you've defined) for a given set of word embeddings trained on a dataset.  What could you do with that score? Brainstorm possible applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incentivize positive word use in a community sharing environment, or parental control on a children gaming platform, banning words that are scored lower at a certain threashold, and rewardc positive attitude and word choices. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
