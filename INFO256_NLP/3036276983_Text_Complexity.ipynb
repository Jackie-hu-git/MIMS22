{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89dd4ae7",
   "metadata": {},
   "source": [
    "Common measures of textual complexity are derived from simple counts of words, sentences and syllables.  In this homework, you'll implement two of them: type-token ratio (a measure of vocabulary richness) and the [Flesch-Kincaid Grade Level](https://en.wikipedia.org/wiki/Flesch–Kincaid_readability_tests#Flesch–Kincaid_grade_level)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e71628d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re, warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f4944f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\12062\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you haven't downloaded the sentence segmentation model before, do so here\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1220bfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a7820e",
   "metadata": {},
   "source": [
    "Q1: Find two different texts you'd like to compare (from any source).  For potential sources, see the [The American Presidency Project](https://www.presidency.ucsb.edu/documents/presidential-documents-archive-guidebook/annual-messages-congress-the-state-the-union) for all state of the union addresses and [Project Gutenberg](https://www.gutenberg.org) for books in the public domain.  Paste them in the `text1` and `text2` strings below.  Ensure that both texts are a minimum of 500 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63adb141",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1=\"\"\" “Let your mind become a lens, thanks to the converging rays of attention; let your soul be all intent on whatever it is that is established in your mind as a dominant, wholly\n",
    "absorbing idea.” This advice comes from Antonin-Dalmace Sertillanges, a Dominican friar and professor of moral philosophy, who during the early part of the twentieth century\n",
    "penned a slim but influential volume titled The Intellectual Life. Sertillanges wrote the book as a guide to “the development and deepening of the mind” for those called to\n",
    "make a living in the world of ideas. Throughout The Intellectual Life, Sertillanges recognizes the necessity of mastering complicated material and helps prepare the\n",
    "reader for this challenge. For this reason, his book proves useful in our quest to better understand how people quickly master hard (cognitive) skills.\n",
    "To understand Sertillanges’s advice, let’s return to the quote from earlier. In these words, which are echoed in many forms in The Intellectual Life, Sertillanges argues\n",
    "that to advance your understanding of your field you must tackle the relevant topics systematically, allowing your “converging rays of attention” to uncover the truth latent\n",
    "in each. In other words, he teaches: To learn requires intense concentration . This idea turns out to be ahead of its time. In reflecting on the life of the mind in the 1920s,\n",
    "Sertillanges uncovered a fact about mastering cognitively demanding tasks that would take academia another seven decades to formalize.\n",
    "This task of formalization began in earnest in the 1970s, when a branch of psychology, sometimes called performance psychology, began to systematically\n",
    "explore what separates experts (in many different fields) from everyone else. In the early 1990s, K. Anders Ericsson, a professor at Florida State University, pulled\n",
    "together these strands into a single coherent answer, consistent with the growing research literature, that he gave a punchy name: deliberate practice.\n",
    "Ericsson opens his seminal paper on the topic with a powerful claim: “We deny that these differences [between expert performers and normal adults] are immutable…\n",
    "Instead, we argue that the differences between expert performers and normal adults reflect a life-long period of deliberate effort to improve performance in a specific\n",
    "domain.” American culture, in particular, loves the storyline of the prodigy (“Do you know how easy this is for me!?” Matt Damon’s character famously cries in the movie Good\n",
    "Will Hunting as he makes quick work of proofs that stymie the world’s top mathematicians). The line of research promoted by Ericsson, and now widely\n",
    "accepted (with caveats *), de-stabilizes these myths. To master a cognitively demanding task requires this specific form of practice—there are few exceptions\n",
    "made for natural talent. (On this point too, Sertillanges seems to have been ahead of his time, arguing in The Intellectual Life, “Men of genius themselves were great only\n",
    "by bringing all their power to bear on the point on which they had decided to show their full measure.” Ericsson couldn’t have said it better.)\n",
    "This brings us to the question of what deliberate practice actually requires. Its core components are usually identified as follows: (1) your attention is focused tightly on a\n",
    "specific skill you’re trying to improve or an idea you’re trying to master; (2) you receive feedback so you can correct your approach to keep your attention exactly\n",
    "where it’s most productive. The first component is of particular importance to our discussion, as it emphasizes that deliberate practice cannot exist alongside distraction,\n",
    "and that it instead requires uninterrupted concentration. As Ericsson emphasizes, “Diffused attention is almost antithetical to the focused attention required by\n",
    "deliberate practice” (emphasis mine). \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d080408",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2=\"\"\"The deified Augustus, to whom the gods granted more than to anyone else, never ceased to pray for rest \n",
    "and to seek a respite from public affairs. Everything he said always reverted to this theme - his hope for leisure. \n",
    "He used to beguile his labours with this consolation, sweet though false, that one day he would live to please \n",
    "himself. In a letter he wrote to the senate, after he promised that his rest would not be lacking in dignity \n",
    "nor inconsistent with his former glory, I find these words: 'But it is more impressive to carry out these things \n",
    "than to promise them. Nevertheless, since the delightful reality is still a long way off, my longing for that much \n",
    "desired time has led me to anticipate some of its delight by the pleasure arising from words.' So valuable did \n",
    "leisure seem to him that because he could not enjoy it in actuality, he did so mentally in advance. He who saw \n",
    "that everything depended on himself alone, who decided the fortune of individuals and nations, was happiest \n",
    "when thinking of that day on which he would lay aside his own greatness. He knew from experience how much \n",
    "sweat those blessings gleaming through every land cost him, how many secret anxieties they concealed. He was \n",
    "forced to fight first with his fellow-countrymen, then with his colleagues, and finally with his relations, \n",
    "shedding blood on land and sea. Driven to fight in Macedonia, \n",
    "Sicily, Egypt, Syria, Asia - almost every country - he turned his armies against foreign enemies when they \n",
    "were tired of shedding Roman blood. While he was establishing peace in the Alps and subduing enemies \n",
    "established in the middle of his peaceful empire; while he was extending his boundaries beyond the Rhine, \n",
    "the Euphrates and the Danube, at Rome itself Murena, Caepio, Lepidus, Egnatius and others were sharpening \n",
    "their swords against him. Nor had he yet escaped their plots when his daughter and all the noble youths bound \n",
    "to her by adultery as though by an oath kept alarming his feeble old age, as did Iullus and a second formidable \n",
    "woman linked to an Antony. He cut away these ulcers, limbs and all, but others took their place: just like a body \n",
    "with a surfeit of blood which is always subject to a haemorrhage somewhere. So he longed for leisure, and \n",
    "as his hopes and thoughts dwelt on that he found relief for his labours: this was the prayer of the man who could \n",
    "grant the prayers of mankind. When Marcus Cicero was cast among men like Cati\u0002line and Clodius and Pompey and Crassus - some of \n",
    "them undisguised enemies and some doubtful friends - when he was tossed about in the storm that struck the \n",
    "state, he tried to hold it steady as it went to its doom; but at last he was swept away. He had neither peace in \n",
    "prosperity nor patience in adversity, and how often does he curse that very consulship, which he had praised \n",
    "without ceasing though not without good reason! What woeful words he uses in a letter to Atticus when the \n",
    "elder Pompey had been conquered, and his son was still trying to revive his defeated forces in Spain! 'Do you \n",
    "want to know,' he said, 'what I am doing here? I am staying a semi-prisoner in my Tusculan villa/ He then \n",
    "goes on to bewail his former life, to complain of the present, and to despair of the future. Cicero called himself \n",
    "a semi-prisoner, but really and truly the wise man will never go so far as to use such an abject term. He will \n",
    "never be a semi-prisoner, but will always enjoy freedom which is solid and complete, at liberty to be his own \n",
    "master and higher than all others. For what can be above the man who is above fortune?  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7020c0bd",
   "metadata": {},
   "source": [
    "Q2: Use the `nltk.word_tokenize` method to implement the type-token ratio:\n",
    "\n",
    "$$\n",
    "TTR = {\\textrm{number of distinct word types} \\over \\textrm{number of word tokens}}\n",
    "$$\n",
    "\n",
    "TTR is dependent on text length (intuitively, the longer a text is, the greater chance you have of a word type repeating), so this number is only comparable between documents of identical lengths.  Calculate this measure for the first 500 words of your two documents and report the results here. Exclude tokens that are exclusively punctuation from all counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "328dd2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_line = \" Driven to fight in Macedonia, Sicily, Egypt, Syria, Asia - almost every country - he turned his armies against foreign enemies when they were tired of shedding Roman blood. While he was establishing peace in the Alps and subduing enemies established in the middle of his peaceful empire; while he was extending his boundaries beyond the Rhine, the Euphrates and the Danube, at Rome itself Murena, Caepio, Lepidus, Egnatius and others were sharpening their swords against him. Nor had he yet escaped their plots when his daughter and all the noble youths bound to her by adultery as though by an oath kept alarming his feeble old age, as did Iullus and a second formidable woman linked to an Antony. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e53728dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove punctuaiton from string \n",
    "def remove_punc(text):\n",
    "    \n",
    "    # initializing punctuations string\n",
    "    punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    \n",
    "    #remove punc if see one\n",
    "    for i in text:\n",
    "        if i in punc:\n",
    "            text = text.replace(i, '')\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f542d183",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the number of words\n",
    "def count_num_words(text):\n",
    "    line_list = []\n",
    "    words = text.split()\n",
    "\n",
    "    for i in words:\n",
    "        line_list.append(i)\n",
    "        \n",
    "    return len(line_list), line_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09827a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the number of distinct words (type)\n",
    "def count_type(text):\n",
    "    dist_word_list = []\n",
    "    words = text.split()\n",
    "\n",
    "    for i in words:\n",
    "        if i not in dist_word_list: \n",
    "            dist_word_list.append(i)\n",
    "        \n",
    "    return len(dist_word_list), dist_word_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "769c6977",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count number of tokens\n",
    "\n",
    "def count_token(text):\n",
    "\n",
    "    token = nltk.word_tokenize(text, language= 'english')\n",
    "        \n",
    "    return len(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f9bee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_token_ratio(text, num_words=500):\n",
    "    # your answer here\n",
    "    \n",
    "    #lower case the text and remove punctuations, and strip it to length of 500\n",
    "    text_no_punc = remove_punc(text.lower())\n",
    "    text_here = text_no_punc[:num_words]\n",
    "    \n",
    "    #get the number of type and tokens \n",
    "    num_type, text_list = count_type(text_here)\n",
    "    num_token = count_token(text_here)\n",
    "    \n",
    "    return (num_type/num_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d84ef059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7590361445783133"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_token_ratio(test_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cdd3b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7303370786516854"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_token_ratio(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28e7e22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7311827956989247"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_token_ratio(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ec573a",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7554c8c5",
   "metadata": {},
   "source": [
    "Now we'll implement the [Flesch-Kincaid Grade Level](https://en.wikipedia.org/wiki/Flesch–Kincaid_readability_tests#Flesch–Kincaid_grade_level), which has the following formula:\n",
    "\n",
    "$$\n",
    "0.39 \\left ( \\frac{\\mbox{total words}}{\\mbox{total sentences}} \\right ) + 11.8 \\left ( \\frac{\\mbox{total syllables}}{\\mbox{total words}} \\right ) - 15.59\n",
    "$$\n",
    "\n",
    "Use `nltk.sent_tokenize` or spacy's `sents` function for counting the number of sentences, any word tokenization method we've covered for counting the number of words, and the `get_syllable_count` function below for counting the number of syllables in a word.  Exclude tokens that are exclusively punctuation from word and syllable counts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62b2be7",
   "metadata": {},
   "source": [
    "For calculating the syllables, we're going to use a number of resources: the [CMU pronunciation dictionary](https://github.com/cmusphinx/cmudict), which lists the ARPABET pronunciation for a list of words, along with [g2p](https://github.com/Kyubyong/g2p), a neural model trained to predict the pronunciation for words (which we can use for words not in the CMU dictionary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e404cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "arpabet = nltk.corpus.cmudict.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c28afcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: g2p_en in c:\\users\\12062\\anaconda3\\envs\\anlp\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: distance>=0.1.3 in c:\\users\\12062\\anaconda3\\envs\\anlp\\lib\\site-packages (from g2p_en) (0.1.3)\n",
      "Requirement already satisfied: nltk>=3.2.4 in c:\\users\\12062\\anaconda3\\envs\\anlp\\lib\\site-packages (from g2p_en) (3.6.2)\n",
      "Requirement already satisfied: numpy>=1.13.1 in c:\\users\\12062\\anaconda3\\envs\\anlp\\lib\\site-packages (from g2p_en) (1.20.3)\n",
      "Requirement already satisfied: inflect>=0.3.1 in c:\\users\\12062\\anaconda3\\envs\\anlp\\lib\\site-packages (from g2p_en) (5.3.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\12062\\anaconda3\\envs\\anlp\\lib\\site-packages (from nltk>=3.2.4->g2p_en) (4.62.1)\n",
      "Requirement already satisfied: click in c:\\users\\12062\\anaconda3\\envs\\anlp\\lib\\site-packages (from nltk>=3.2.4->g2p_en) (8.0.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\12062\\anaconda3\\envs\\anlp\\lib\\site-packages (from nltk>=3.2.4->g2p_en) (1.0.1)\n",
      "Requirement already satisfied: regex in c:\\users\\12062\\anaconda3\\envs\\anlp\\lib\\site-packages (from nltk>=3.2.4->g2p_en) (2021.8.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\12062\\anaconda3\\envs\\anlp\\lib\\site-packages (from click->nltk>=3.2.4->g2p_en) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install g2p_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd5eea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from g2p_en import G2p\n",
    "g2p = G2p()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adb9196c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pronunciation(word):\n",
    "    if word in arpabet:\n",
    "        # pick the first pronunciation\n",
    "        return arpabet[word][0]\n",
    "\n",
    "    else:\n",
    "        return g2p(word)\n",
    "\n",
    "def get_syllable_count(word):\n",
    "    pronunciation=get_pronunciation(word)\n",
    "    sylls=0\n",
    "    for phon in pronunciation:\n",
    "        # vowels in arpabet end in digits (indicating stress)\n",
    "        if re.search(\"\\d$\", phon) is not None:\n",
    "            sylls+=1\n",
    "    return sylls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b43076b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_syllable_count(\"Bamman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6adfab7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_syllable_count(\"The Australian platypus is seemingly a hybrid of a mammal and reptilian creature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fc2ff8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting number of sentece \n",
    "def count_sent(line):\n",
    "    return len(nltk.sent_tokenize(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc8ed59",
   "metadata": {},
   "source": [
    "Q3. Implement Flesch-Kincaid Grade Level and report its results for your two texts.  Flesch-Kincaid relies on an implicit definition of a \"word\" and a \"sentence\", and different definitions will yield different grade level estimates. (In the problem definition above, we've already ruled out punctuation as constituing stand-alone words, and other assumptions lurk with every tokenization method). State your assumptions for the definition of \"word\" you have implemented and why they are reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d56111b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flesch_kincaid_grade_level(text):\n",
    "    # your answer here\n",
    "    total_sent = count_sent(text)\n",
    "    \n",
    "    text_new = remove_punc(text.lower())\n",
    "    total_words, text_list = count_num_words(text_new)\n",
    "    \n",
    "    total_syll = get_syllable_count(text_new)\n",
    "    \n",
    "    return 0.39 * (total_words / total_sent) + 11.8 * (total_syll/total_words) - 15.59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d970aedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.264615384615386"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should be 11.265\n",
    "flesch_kincaid_grade_level(\"The Australian platypus is seemingly a hybrid of a mammal and reptilian creature\".lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04718a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.022581081081082"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flesch_kincaid_grade_level(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3ee45cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.809655172413795"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flesch_kincaid_grade_level(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e6db12",
   "metadata": {},
   "source": [
    "**Q3 \"word\" assumptions:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98304545",
   "metadata": {},
   "source": [
    "Words like \"I'm\", \"let's\" counts as 1 word, since eliminated the punctuation we are concatenating the words together as 1 word.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732cda71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anlp] *",
   "language": "python",
   "name": "conda-env-anlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
